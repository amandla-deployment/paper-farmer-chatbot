{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Garbage collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear IPython's global namespace\n",
    "%reset -f\n",
    "\n",
    "# Reimport gc module\n",
    "import gc\n",
    "# Run garbage collection\n",
    "gc.collect()\n",
    "\n",
    "# Clear all cell outputs\n",
    "from IPython.display import clear_output\n",
    "clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/manimala/Documents/satyakama/paper-farmer-chatbot/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "polars.config.Config"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import polars as pl \n",
    "pl.Config.set_tbl_rows(1000)  # or whatever number of rows you want to see\n",
    "pl.Config.set_tbl_cols(-1)  # Show all columns (-1 means no limit)\n",
    "pl.Config.set_fmt_str_lengths(1000)  # Increase maximum string length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original rows: 41987874\n"
     ]
    }
   ],
   "source": [
    "master_df = pl.read_csv(\n",
    "    source= 'dataset/original_dataset/kcc_dataset.csv',\n",
    "    columns= ['Year',\n",
    "        'Month',\n",
    "        'Day',\n",
    "        'Crop',\n",
    "        'BlockName',\n",
    "        'DistrictName',\n",
    "        'QueryType',\n",
    "        'Season',\n",
    "        'Sector',\n",
    "        'StateName',\n",
    "        'QueryText',\n",
    "        'KccAns'],\n",
    "    has_header= True,\n",
    "    low_memory= True\n",
    "\n",
    "    \n",
    ")\n",
    "\n",
    "# Convert all column values to uppercase\n",
    "master_df = master_df.with_columns([\n",
    "    pl.all().cast(pl.Utf8).str.to_uppercase()\n",
    "])\n",
    "\n",
    "# FILTER LOGIC \n",
    "# Creating a new column for Date\n",
    "master_df = master_df.with_columns(\n",
    "    pl.format(\"{}-{}-{}\", \n",
    "        pl.col(\"Day\").cast(pl.Utf8).str.zfill(2),\n",
    "        pl.col(\"Month\").cast(pl.Utf8).str.zfill(2),\n",
    "        pl.col(\"Year\")\n",
    "    ).str.strptime(pl.Date, format=\"%d-%m-%Y\").alias(\"Date\")\n",
    ")\n",
    "# Drop the 3 redundant columns\n",
    "master_df = master_df.drop(['Day', 'Month', 'Year'])\n",
    "original_rows = master_df.shape[0]\n",
    "print(f\"Original rows: {original_rows}\")\n",
    "\n",
    "master_df = master_df[['QueryText', 'KccAns', 'Date']]\n",
    "\n",
    "# Clean text data by removing extra leading and trailing and in-between whitespaces between words\n",
    "# master_df = master_df.with_columns([\n",
    "#     # First standardize all whitespace to single spaces and remove leading/trailing\n",
    "#     pl.col(\"QueryText\").cast(pl.Utf8)\n",
    "#         .str.replace(r'\\s+', ' ')  # convert multiple spaces to single space\n",
    "#         .str.replace(r'^\\s+', '')  # remove leading spaces\n",
    "#         .str.replace(r'\\s+$', '')  # remove trailing spaces\n",
    "#         .alias(\"QueryText\"),\n",
    "        \n",
    "#     pl.col(\"KccAns\").cast(pl.Utf8)\n",
    "#         .str.replace(r'\\s+', ' ')  # convert multiple spaces to single space\n",
    "#         .str.replace(r'^\\s+', '')  # remove leading spaces\n",
    "#         .str.replace(r'\\s+$', '')  # remove trailing spaces\n",
    "#         .alias(\"KccAns\")\n",
    "# ])\n",
    "\n",
    "master_df = master_df.with_columns([\n",
    "    pl.col(\"QueryText\").cast(pl.Utf8)\n",
    "        .str.replace(r':\\s+', ':')        # remove spaces after colon\n",
    "        .str.replace(r'\\s+', ' ')         # first convert all multiple spaces to single space\n",
    "        .str.replace(r'(\\d+)\\s+(\\d+)', '$1$2')  # remove spaces between numbers, first pass\n",
    "        .str.replace(r'(\\d+)\\s+(\\d+)', '$1$2')  # second pass for remaining number pairs\n",
    "        .str.replace(r'(\\d+)\\s+(\\d+)', '$1$2')  # third pass for any remaining\n",
    "        .str.replace(r'^\\s+', '')         # remove leading spaces\n",
    "        .str.replace(r'\\s+$', '')         # remove trailing spaces\n",
    "        .alias(\"QueryText\"),\n",
    "        \n",
    "    pl.col(\"KccAns\").cast(pl.Utf8)\n",
    "        .str.replace(r':\\s+', ':')        # remove spaces after colon\n",
    "        .str.replace(r'\\s+', ' ')         # first convert all multiple spaces to single space\n",
    "        .str.replace(r'(\\d+)\\s+(\\d+)', '$1$2')  # remove spaces between numbers, first pass\n",
    "        .str.replace(r'(\\d+)\\s+(\\d+)', '$1$2')  # second pass for remaining number pairs\n",
    "        .str.replace(r'(\\d+)\\s+(\\d+)', '$1$2')  # third pass for any remaining\n",
    "        .str.replace(r'^\\s+', '')         # remove leading spaces\n",
    "        .str.replace(r'\\s+$', '')         # remove trailing spaces\n",
    "        .alias(\"KccAns\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>QueryText</th><th>KccAns</th><th>Date</th></tr><tr><td>str</td><td>str</td><td>date</td></tr></thead><tbody><tr><td>&quot;ASKED ABOUT TO FERTILIZER DOSE IN MANGO PLANT&quot;</td><td>&quot;4-625200-400500-700&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;350-700&quot;</td><td>2025-01-18</td></tr><tr><td>&quot;FARMER ASKED QUERY ON WEATHER&quot;</td><td>&quot;:: 28&nbsp;&nbsp;C&nbsp;&nbsp;&nbsp;&nbsp;24 C&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;24&quot;</td><td>2025-01-18</td></tr><tr><td>&quot;ASKED ABOUT HOW LONG AFTER PESTICIDE SPRAYING CAN IT RAIN&quot;</td><td>&quot;:: 6-8&quot;</td><td>2025-01-18</td></tr><tr><td>&quot;ASKING ABOUT&nbsp;&nbsp;LEAF MINER MANAGEMENT IN GROUNDNUT&quot;</td><td>&quot;:: : 12&quot;</td><td>2025-01-19</td></tr><tr><td>&quot;ASKED ABOUT LEAF CATERPILLAR MANAGEMENT FOR GROUNDNUT&quot;</td><td>&quot;:: : 12&quot;</td><td>2025-01-19</td></tr><tr><td>&quot;ASKED ABOUT LEAF SPOT CONTROL IN GROUNDNUT&quot;</td><td>&quot;::&nbsp;&nbsp;12&quot;</td><td>2025-01-19</td></tr><tr><td>&quot;FARMER ASKED QUERY ON WEATHER&quot;</td><td>&quot;::&nbsp;&nbsp;&nbsp;324 -2726&quot;</td><td>2025-01-18</td></tr><tr><td>&quot;ASKED ABOUT BUTTON SHEDDING MANAGEMENT IN COCONUT&quot;</td><td>&quot;::&nbsp;&nbsp;&nbsp;&nbsp;2001&quot;</td><td>2025-01-18</td></tr><tr><td>&quot;FARMER ASKED QUERY ON WEATHER&quot;</td><td>&quot;::&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;272427&quot;</td><td>2025-01-18</td></tr><tr><td>&quot;FARMER ASKED QUERY ON WEATHER&quot;</td><td>&quot;::&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;28 -2318&quot;</td><td>2025-01-18</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 3)\n",
       "┌──────────────────────────────────────────────────┬──────────────────────────────────┬────────────┐\n",
       "│ QueryText                                        ┆ KccAns                           ┆ Date       │\n",
       "│ ---                                              ┆ ---                              ┆ ---        │\n",
       "│ str                                              ┆ str                              ┆ date       │\n",
       "╞══════════════════════════════════════════════════╪══════════════════════════════════╪════════════╡\n",
       "│ ASKED ABOUT TO FERTILIZER DOSE IN MANGO PLANT    ┆ 4-625200-400500-700      350-700 ┆ 2025-01-18 │\n",
       "│ FARMER ASKED QUERY ON WEATHER                    ┆ :: 28  C    24 C     24          ┆ 2025-01-18 │\n",
       "│ ASKED ABOUT HOW LONG AFTER PESTICIDE SPRAYING    ┆ :: 6-8                           ┆ 2025-01-18 │\n",
       "│ CAN IT RAIN                                      ┆                                  ┆            │\n",
       "│ ASKING ABOUT  LEAF MINER MANAGEMENT IN GROUNDNUT ┆ :: : 12                          ┆ 2025-01-19 │\n",
       "│ ASKED ABOUT LEAF CATERPILLAR MANAGEMENT FOR      ┆ :: : 12                          ┆ 2025-01-19 │\n",
       "│ GROUNDNUT                                        ┆                                  ┆            │\n",
       "│ ASKED ABOUT LEAF SPOT CONTROL IN GROUNDNUT       ┆ ::  12                           ┆ 2025-01-19 │\n",
       "│ FARMER ASKED QUERY ON WEATHER                    ┆ ::   324 -2726                   ┆ 2025-01-18 │\n",
       "│ ASKED ABOUT BUTTON SHEDDING MANAGEMENT IN        ┆ ::    2001                       ┆ 2025-01-18 │\n",
       "│ COCONUT                                          ┆                                  ┆            │\n",
       "│ FARMER ASKED QUERY ON WEATHER                    ┆ ::                272427         ┆ 2025-01-18 │\n",
       "│ FARMER ASKED QUERY ON WEATHER                    ┆ ::               28 -2318        ┆ 2025-01-18 │\n",
       "└──────────────────────────────────────────────────┴──────────────────────────────────┴────────────┘"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = master_df.tail(2000)\n",
    "\n",
    "master_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with 41987874 rows\n",
      "Starting cleaning process...\n",
      "Rows after basic cleaning: 28721963\n",
      "Loading SentenceTransformer model...\n",
      "Generating embeddings for KccAns...\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 49\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Apply the cleaning with progress tracking\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmaster_df\u001b[38;5;241m.\u001b[39mheight\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m rows\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 49\u001b[0m cleaned_df \u001b[38;5;241m=\u001b[39m \u001b[43mclean_responses\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaster_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFinal Results:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal rows: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmaster_df\u001b[38;5;241m.\u001b[39mheight\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[45], line 25\u001b[0m, in \u001b[0;36mclean_responses\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     23\u001b[0m kcc_answers \u001b[38;5;241m=\u001b[39m valid_answers[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKccAns\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto_list()\n\u001b[1;32m     24\u001b[0m kcc_embeddings \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkcc_answers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEncoding KccAns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     26\u001b[0m     kcc_embeddings\u001b[38;5;241m.\u001b[39mappend(model\u001b[38;5;241m.\u001b[39mencode(text))\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerating embeddings for QueryText...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/rag/lib/python3.11/site-packages/tqdm/notebook.py:234\u001b[0m, in \u001b[0;36mtqdm_notebook.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m unit_scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munit_scale \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munit_scale \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    233\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;241m*\u001b[39m unit_scale \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal\n\u001b[0;32m--> 234\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_printer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mncols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer\u001b[38;5;241m.\u001b[39mpbar \u001b[38;5;241m=\u001b[39m proxy(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/rag/lib/python3.11/site-packages/tqdm/notebook.py:108\u001b[0m, in \u001b[0;36mtqdm_notebook.status_printer\u001b[0;34m(_, total, desc, ncols)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# Fallback to text bar if there's no total\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# DEPRECATED: replaced with an 'info' style bar\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m# if not total:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# Prepare IPython progress bar\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m IProgress \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# #187 #451 #558 #872\u001b[39;00m\n\u001b[0;32m--> 108\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(WARN_NOIPYW)\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m total:\n\u001b[1;32m    110\u001b[0m     pbar \u001b[38;5;241m=\u001b[39m IProgress(\u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39mtotal)\n",
      "\u001b[0;31mImportError\u001b[0m: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import polars as pl\n",
    "\n",
    "def clean_responses(df):\n",
    "    print(\"Starting cleaning process...\")\n",
    "    \n",
    "    # 1. Basic cleaning\n",
    "    valid_answers = df.filter(\n",
    "        (pl.col(\"KccAns\").is_not_null() & pl.col(\"KccAns\").str.contains(r'[a-zA-Z]')) &\n",
    "        (pl.col(\"QueryText\").is_not_null() & pl.col(\"QueryText\").str.contains(r'[a-zA-Z]'))\n",
    "    )\n",
    "    print(f\"Rows after basic cleaning: {valid_answers.height}\")\n",
    "    \n",
    "    # 2. Initialize model\n",
    "    print(\"Loading SentenceTransformer model...\")\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    \n",
    "    # 3. Get embeddings for both columns with tqdm\n",
    "    print(\"Generating embeddings for KccAns...\")\n",
    "    kcc_answers = valid_answers['KccAns'].to_list()\n",
    "    kcc_embeddings = []\n",
    "    for text in tqdm(kcc_answers, desc=\"Encoding KccAns\"):\n",
    "        kcc_embeddings.append(model.encode(text))\n",
    "    \n",
    "    print(\"Generating embeddings for QueryText...\")\n",
    "    query_texts = valid_answers['QueryText'].to_list()\n",
    "    query_embeddings = []\n",
    "    for text in tqdm(query_texts, desc=\"Encoding QueryText\"):\n",
    "        query_embeddings.append(model.encode(text))\n",
    "    \n",
    "    # 4. Combine embeddings\n",
    "    combined_embeddings = np.concatenate([kcc_embeddings, query_embeddings], axis=1)\n",
    "    \n",
    "    # 5. Use Isolation Forest to detect outliers\n",
    "    print(\"Detecting outliers...\")\n",
    "    iso_forest = IsolationForest(contamination=0.1, random_state=42)\n",
    "    predictions = iso_forest.fit_predict(combined_embeddings)\n",
    "    \n",
    "    # 6. Keep only good responses\n",
    "    cleaned_df = valid_answers.filter(pl.Series(predictions == 1))\n",
    "    \n",
    "    return cleaned_df\n",
    "\n",
    "# Apply the cleaning with progress tracking\n",
    "print(f\"Starting with {master_df.height} rows\")\n",
    "cleaned_df = clean_responses(master_df)\n",
    "print(f\"\\nFinal Results:\")\n",
    "print(f\"Original rows: {master_df.height}\")\n",
    "print(f\"Cleaned rows: {cleaned_df.height}\")\n",
    "print(f\"Removed {master_df.height - cleaned_df.height} rows\")\n",
    "\n",
    "# Look at some examples\n",
    "print(\"\\nExample cleaned responses:\")\n",
    "print(\"\\nKccAns examples:\")\n",
    "print(cleaned_df['KccAns'].head(3))\n",
    "print(\"\\nQueryText examples:\")\n",
    "print(cleaned_df['QueryText'].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-8.1.5-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: comm>=0.1.3 in /home/manimala/miniconda3/envs/rag/lib/python3.11/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /home/manimala/miniconda3/envs/rag/lib/python3.11/site-packages (from ipywidgets) (8.31.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/manimala/miniconda3/envs/rag/lib/python3.11/site-packages (from ipywidgets) (5.14.3)\n",
      "Collecting widgetsnbextension~=4.0.12 (from ipywidgets)\n",
      "  Downloading widgetsnbextension-4.0.13-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab-widgets~=3.0.12 (from ipywidgets)\n",
      "  Downloading jupyterlab_widgets-3.0.13-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: decorator in /home/manimala/miniconda3/envs/rag/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/manimala/miniconda3/envs/rag/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /home/manimala/miniconda3/envs/rag/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/manimala/miniconda3/envs/rag/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /home/manimala/miniconda3/envs/rag/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/manimala/miniconda3/envs/rag/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
      "Requirement already satisfied: stack_data in /home/manimala/miniconda3/envs/rag/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in /home/manimala/miniconda3/envs/rag/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (4.12.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /home/manimala/miniconda3/envs/rag/lib/python3.11/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/manimala/miniconda3/envs/rag/lib/python3.11/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/manimala/miniconda3/envs/rag/lib/python3.11/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/manimala/miniconda3/envs/rag/lib/python3.11/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/manimala/miniconda3/envs/rag/lib/python3.11/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in /home/manimala/miniconda3/envs/rag/lib/python3.11/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Downloading ipywidgets-8.1.5-py3-none-any.whl (139 kB)\n",
      "Downloading jupyterlab_widgets-3.0.13-py3-none-any.whl (214 kB)\n",
      "Downloading widgetsnbextension-4.0.13-py3-none-any.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: widgetsnbextension, jupyterlab-widgets, ipywidgets\n",
      "Successfully installed ipywidgets-8.1.5 jupyterlab-widgets-3.0.13 widgetsnbextension-4.0.13\n"
     ]
    }
   ],
   "source": [
    "! pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import numpy as np\n",
    "\n",
    "def clean_responses(df):\n",
    "    # 1. Basic cleaning\n",
    "    valid_answers = df.filter(\n",
    "        pl.col(\"KccAns\").is_not_null() &\n",
    "        pl.col(\"KccAns\").str.contains(r'[a-zA-Z]')\n",
    "    )\n",
    "    \n",
    "    # 2. Get embeddings\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    embeddings = model.encode(valid_answers['KccAns'].to_list())\n",
    "    \n",
    "    # 3. Use Isolation Forest to detect outliers\n",
    "    iso_forest = IsolationForest(contamination=0.1, random_state=42)\n",
    "    predictions = iso_forest.fit_predict(embeddings)\n",
    "    \n",
    "    # 4. Keep only good responses using filter instead of boolean indexing\n",
    "    cleaned_df = valid_answers.filter(pl.Series(predictions == 1))\n",
    "    \n",
    "    return cleaned_df\n",
    "\n",
    "# Apply the cleaning\n",
    "cleaned_df = clean_responses(master_df)\n",
    "print(f\"Original rows: {master_df.height}\")\n",
    "print(f\"Cleaned rows: {cleaned_df.height}\")\n",
    "\n",
    "# Look at some examples\n",
    "print(\"\\nExample cleaned responses:\")\n",
    "print(cleaned_df['KccAns'].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df.tail(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[master_df['KccAns'].head(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just get top 50 values and their counts\n",
    "# Basic value counts with percentage\n",
    "value_counts = (\n",
    "    master_df.get_column(\"Season\")\n",
    "    .value_counts(parallel=True)\n",
    "    .with_columns([\n",
    "        (pl.col(\"count\") / pl.col(\"count\").sum() * 100).alias(\"percentage\")  # Note: \"count\" not \"counts\"\n",
    "    ])\n",
    "    .sort(\"count\", descending=True) \n",
    "    .head(50)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = master_df.filter(pl.col(\"Crop\") == \"Others\")\n",
    "\n",
    "filtered_df['QueryText', 'KccAns'].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
