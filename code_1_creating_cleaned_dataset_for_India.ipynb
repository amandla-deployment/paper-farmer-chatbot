{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import psutil\n",
    "import os\n",
    "import gc\n",
    "from typing import Dict, Optional, Union, List\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_memory(df_to_remove: Optional[Union[pl.DataFrame, List[pl.DataFrame]]] = None) -> None:\n",
    "    \"\"\"\n",
    "    Clear memory and print memory usage statistics\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Print initial state\n",
    "        print(\"\\nInitial memory state:\")\n",
    "        process = psutil.Process(os.getpid())\n",
    "        initial_memory_mb = process.memory_info().rss / 1024 / 1024\n",
    "        print(f\"Current Memory Usage: {initial_memory_mb:.2f} MB ({initial_memory_mb/1024:.2f} GB)\")\n",
    "        \n",
    "        # Remove specific DataFrame if provided\n",
    "        if df_to_remove is not None:\n",
    "            if isinstance(df_to_remove, list):\n",
    "                for df in df_to_remove:\n",
    "                    # Get the variable name\n",
    "                    name = [var_name for var_name, var_val in globals().items() if var_val is df]\n",
    "                    if name:\n",
    "                        globals().pop(name[0], None)\n",
    "                    del df\n",
    "            else:\n",
    "                name = [var_name for var_name, var_val in globals().items() if var_val is df_to_remove]\n",
    "                if name:\n",
    "                    globals().pop(name[0], None)\n",
    "                del df_to_remove\n",
    "                \n",
    "        # Force garbage collection\n",
    "        gc.collect()\n",
    "        \n",
    "        # Get new memory info\n",
    "        new_memory_mb = process.memory_info().rss / 1024 / 1024\n",
    "        memory_freed = initial_memory_mb - new_memory_mb\n",
    "        \n",
    "        print(f\"\\nCurrent Memory Usage: {new_memory_mb:.2f} MB ({new_memory_mb/1024:.2f} GB)\")\n",
    "        print(f\"Available System Memory: {psutil.virtual_memory().available / 1024 / 1024 / 1024:.2f} GB\")\n",
    "        print(f\"Memory Utilization: {psutil.virtual_memory().percent}%\")\n",
    "        \n",
    "        if memory_freed > 0:\n",
    "            print(f\"Memory freed: {memory_freed:.2f} MB\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Memory cleanup failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third cell - Define load_data function\n",
    "def load_data(\n",
    "    file_path: str,\n",
    "    schema_overrides: Optional[Dict] = None,\n",
    "    columns_to_drop: Optional[List[str]] = None,\n",
    "    low_memory: bool = True\n",
    ") -> Optional[pl.DataFrame]:\n",
    "    \"\"\"\n",
    "    Load and process a CSV file using Polars\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the CSV file\n",
    "        schema_overrides: Dictionary of column names and their data types\n",
    "        columns_to_drop: List of column names to drop\n",
    "        low_memory: Whether to use low memory mode\n",
    "    \n",
    "    Returns:\n",
    "        Processed Polars DataFrame or None if error occurs\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Ensure file exists\n",
    "        if not Path(file_path).exists():\n",
    "            raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "            \n",
    "        print(\"Initial memory state:\")\n",
    "        clear_memory()\n",
    "        \n",
    "        print(\"\\nLoading CSV file...\")\n",
    "        # Read CSV with provided schema overrides\n",
    "        df = pl.read_csv(\n",
    "            file_path,\n",
    "            schema_overrides=schema_overrides or {},\n",
    "            low_memory=low_memory\n",
    "        )\n",
    "        \n",
    "        # Drop specified columns if any\n",
    "        if columns_to_drop:\n",
    "            df = df.drop(columns_to_drop)\n",
    "            \n",
    "        print(\"\\nAfter loading CSV:\")\n",
    "        clear_memory()\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in data processing: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial memory state:\n",
      "\n",
      "Initial memory state:\n",
      "Current Memory Usage: 82.55 MB (0.08 GB)\n",
      "\n",
      "Current Memory Usage: 82.55 MB (0.08 GB)\n",
      "Available System Memory: 245.69 GB\n",
      "Memory Utilization: 2.1%\n",
      "\n",
      "Loading CSV file...\n",
      "\n",
      "After loading CSV:\n",
      "\n",
      "Initial memory state:\n",
      "Current Memory Usage: 11778.02 MB (11.50 GB)\n",
      "\n",
      "Current Memory Usage: 11778.02 MB (11.50 GB)\n",
      "Available System Memory: 234.15 GB\n",
      "Memory Utilization: 6.7%\n"
     ]
    }
   ],
   "source": [
    "# Define schema overrides for your specific CSV\n",
    "schema = {\n",
    "    'Year': pl.Int32,\n",
    "    'Month': pl.Int32,\n",
    "    'Day': pl.Int32,\n",
    "    'Crop': pl.Utf8,\n",
    "    'DistrictName': pl.Utf8,\n",
    "    'QueryType': pl.Utf8,\n",
    "    'Season': pl.Utf8,\n",
    "    'Sector': pl.Utf8,\n",
    "    'StateName': pl.Utf8,\n",
    "    'QueryText': pl.Utf8,\n",
    "    'KccAns': pl.Utf8,\n",
    "    'Category': pl.Utf8,\n",
    "    'BlockName': pl.Utf8\n",
    "}\n",
    "\n",
    "# Specify columns to drop\n",
    "columns_to_drop = ['BlockName', 'Category']\n",
    "\n",
    "# Load your data (replace with your actual file path)\n",
    "master_df = load_data(\n",
    "    file_path='dataset/original_dataset/kcc_dataset.csv',  # Replace with your actual file path\n",
    "    schema_overrides=schema,\n",
    "    columns_to_drop=columns_to_drop,\n",
    "    low_memory=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 11)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Year</th><th>Month</th><th>Day</th><th>Crop</th><th>DistrictName</th><th>QueryType</th><th>Season</th><th>Sector</th><th>StateName</th><th>QueryText</th><th>KccAns</th></tr><tr><td>i32</td><td>i32</td><td>i32</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>2006</td><td>1</td><td>17</td><td>&quot;1275&quot;</td><td>&quot;SAGAR&quot;</td><td>&quot;99&quot;</td><td>&quot;RABI&quot;</td><td>&quot;HORTICULTURE&quot;</td><td>&quot;MADHYA PRADESH&quot;</td><td>&quot;how to control flower drop in …</td><td>&quot;spray planofix4mlpump&quot;</td></tr><tr><td>2006</td><td>1</td><td>17</td><td>&quot;964&quot;</td><td>&quot;SAGAR&quot;</td><td>&quot;Disease Management&quot;</td><td>&quot;RABI&quot;</td><td>&quot;ANIMAL HUSBANDRY&quot;</td><td>&quot;MADHYA PRADESH&quot;</td><td>&quot;how tyo control diseases in bu…</td><td>null</td></tr><tr><td>2006</td><td>1</td><td>17</td><td>&quot;1279&quot;</td><td>&quot;SAGAR&quot;</td><td>&quot;76&quot;</td><td>&quot;RABI&quot;</td><td>&quot;HORTICULTURE&quot;</td><td>&quot;MADHYA PRADESH&quot;</td><td>&quot;how to control fruit borer in …</td><td>&quot;should be spray profenophos 35…</td></tr><tr><td>2006</td><td>1</td><td>17</td><td>&quot;1064&quot;</td><td>&quot;SAGAR&quot;</td><td>&quot;3&quot;</td><td>&quot;RABI&quot;</td><td>&quot;AGRICULTURE&quot;</td><td>&quot;MADHYA PRADESH&quot;</td><td>&quot;how to control of yellow moisa…</td><td>&quot;should be spray metasystox 35m…</td></tr><tr><td>2006</td><td>1</td><td>17</td><td>&quot;1279&quot;</td><td>&quot;DAMOH&quot;</td><td>&quot;76&quot;</td><td>&quot;RABI&quot;</td><td>&quot;HORTICULTURE&quot;</td><td>&quot;MADHYA PRADESH&quot;</td><td>&quot;how to control white fly in br…</td><td>&quot;should be spray metasystox 35m…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 11)\n",
       "┌──────┬───────┬─────┬──────┬───┬──────────────┬───────────┬───────────────────┬───────────────────┐\n",
       "│ Year ┆ Month ┆ Day ┆ Crop ┆ … ┆ Sector       ┆ StateName ┆ QueryText         ┆ KccAns            │\n",
       "│ ---  ┆ ---   ┆ --- ┆ ---  ┆   ┆ ---          ┆ ---       ┆ ---               ┆ ---               │\n",
       "│ i32  ┆ i32   ┆ i32 ┆ str  ┆   ┆ str          ┆ str       ┆ str               ┆ str               │\n",
       "╞══════╪═══════╪═════╪══════╪═══╪══════════════╪═══════════╪═══════════════════╪═══════════════════╡\n",
       "│ 2006 ┆ 1     ┆ 17  ┆ 1275 ┆ … ┆ HORTICULTURE ┆ MADHYA    ┆ how to control    ┆ spray             │\n",
       "│      ┆       ┆     ┆      ┆   ┆              ┆ PRADESH   ┆ flower drop in …  ┆ planofix4mlpump   │\n",
       "│ 2006 ┆ 1     ┆ 17  ┆ 964  ┆ … ┆ ANIMAL       ┆ MADHYA    ┆ how tyo control   ┆ null              │\n",
       "│      ┆       ┆     ┆      ┆   ┆ HUSBANDRY    ┆ PRADESH   ┆ diseases in bu…   ┆                   │\n",
       "│ 2006 ┆ 1     ┆ 17  ┆ 1279 ┆ … ┆ HORTICULTURE ┆ MADHYA    ┆ how to control    ┆ should be spray   │\n",
       "│      ┆       ┆     ┆      ┆   ┆              ┆ PRADESH   ┆ fruit borer in …  ┆ profenophos 35…   │\n",
       "│ 2006 ┆ 1     ┆ 17  ┆ 1064 ┆ … ┆ AGRICULTURE  ┆ MADHYA    ┆ how to control of ┆ should be spray   │\n",
       "│      ┆       ┆     ┆      ┆   ┆              ┆ PRADESH   ┆ yellow moisa…     ┆ metasystox 35m…   │\n",
       "│ 2006 ┆ 1     ┆ 17  ┆ 1279 ┆ … ┆ HORTICULTURE ┆ MADHYA    ┆ how to control    ┆ should be spray   │\n",
       "│      ┆       ┆     ┆      ┆   ┆              ┆ PRADESH   ┆ white fly in br…  ┆ metasystox 35m…   │\n",
       "└──────┴───────┴─────┴──────┴───┴──────────────┴───────────┴───────────────────┴───────────────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41987874, 11)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Filtering: Null analysis and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_and_clean_nulls(\n",
    "    df: pl.DataFrame,\n",
    "    columns_to_clean: List[str],\n",
    "    fill_nulls: Dict[str, str] = None\n",
    ") -> tuple[pl.DataFrame, pl.DataFrame]:\n",
    "    \"\"\"\n",
    "    Analyze null values in a DataFrame and clean them according to specified rules.\n",
    "    \n",
    "    Args:\n",
    "        df: Input Polars DataFrame\n",
    "        columns_to_clean: List of column names where nulls should be dropped\n",
    "        fill_nulls: Dictionary of {column_name: fill_value} for replacing nulls\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (cleaned_df, null_analysis_df)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Store original shape for comparison\n",
    "        total_rows = df.shape[0]\n",
    "        print(f\"Original shape: {df.shape}\")\n",
    "        \n",
    "        # Create null value analysis DataFrame\n",
    "        null_analysis = (\n",
    "            pl.DataFrame({\n",
    "                'Column': df.columns,\n",
    "                'Total_Values': total_rows,\n",
    "                'Null_Count': df.null_count().row(0),\n",
    "            })\n",
    "            .with_columns([\n",
    "                # Calculate null percentage for each column\n",
    "                (pl.col('Null_Count') / pl.col('Total_Values') * 100)\n",
    "                .round(2)\n",
    "                .alias('Null_Percentage')\n",
    "            ])\n",
    "            .sort('Null_Percentage', descending=True)  # Sort by percentage descending\n",
    "        )\n",
    "        \n",
    "        print(\"\\nNull value analysis:\")\n",
    "        print(null_analysis)\n",
    "        \n",
    "        # Create a copy of the DataFrame for cleaning\n",
    "        cleaned_df = df.clone()\n",
    "        \n",
    "        # Drop nulls from specified columns\n",
    "        if columns_to_clean:\n",
    "            cleaned_df = cleaned_df.drop_nulls(subset=columns_to_clean)\n",
    "            print(f\"\\nShape after removing nulls: {cleaned_df.shape}\")\n",
    "            \n",
    "            # Optional: Verify null removal\n",
    "            null_check = cleaned_df.select(columns_to_clean).null_count()\n",
    "            print(\"\\nNull counts in specified columns after cleaning:\")\n",
    "            print(null_check)\n",
    "        \n",
    "        # Fill nulls in specified columns with provided values\n",
    "        if fill_nulls:\n",
    "            for column, fill_value in fill_nulls.items():\n",
    "                if column in cleaned_df.columns:\n",
    "                    cleaned_df = cleaned_df.with_columns(\n",
    "                        pl.col(column).fill_null(value=fill_value)\n",
    "                    )\n",
    "                    # Print unique values to verify replacement\n",
    "                    print(f\"\\nUnique values in {column} after filling nulls:\")\n",
    "                    print(cleaned_df[column].unique())\n",
    "                else:\n",
    "                    print(f\"\\nWarning: Column '{column}' not found in DataFrame\")\n",
    "        \n",
    "        return cleaned_df, null_analysis\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in analyze_and_clean_nulls: {e}\")\n",
    "        return df, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (41987874, 11)\n",
      "\n",
      "Null value analysis:\n",
      "shape: (11, 4)\n",
      "┌──────────────┬──────────────┬────────────┬─────────────────┐\n",
      "│ Column       ┆ Total_Values ┆ Null_Count ┆ Null_Percentage │\n",
      "│ ---          ┆ ---          ┆ ---        ┆ ---             │\n",
      "│ str          ┆ i32          ┆ i64        ┆ f64             │\n",
      "╞══════════════╪══════════════╪════════════╪═════════════════╡\n",
      "│ Season       ┆ 41987874     ┆ 26665089   ┆ 63.51           │\n",
      "│ KccAns       ┆ 41987874     ┆ 4320412    ┆ 10.29           │\n",
      "│ QueryType    ┆ 41987874     ┆ 1333503    ┆ 3.18            │\n",
      "│ Crop         ┆ 41987874     ┆ 172930     ┆ 0.41            │\n",
      "│ Sector       ┆ 41987874     ┆ 85083      ┆ 0.2             │\n",
      "│ …            ┆ …            ┆ …          ┆ …               │\n",
      "│ Year         ┆ 41987874     ┆ 0          ┆ 0.0             │\n",
      "│ Month        ┆ 41987874     ┆ 0          ┆ 0.0             │\n",
      "│ Day          ┆ 41987874     ┆ 0          ┆ 0.0             │\n",
      "│ DistrictName ┆ 41987874     ┆ 0          ┆ 0.0             │\n",
      "│ StateName    ┆ 41987874     ┆ 0          ┆ 0.0             │\n",
      "└──────────────┴──────────────┴────────────┴─────────────────┘\n",
      "\n",
      "Shape after removing nulls: (36267631, 11)\n",
      "\n",
      "Null counts in specified columns after cleaning:\n",
      "shape: (1, 5)\n",
      "┌────────┬───────────┬──────┬────────┬───────────┐\n",
      "│ KccAns ┆ QueryType ┆ Crop ┆ Sector ┆ QueryText │\n",
      "│ ---    ┆ ---       ┆ ---  ┆ ---    ┆ ---       │\n",
      "│ u32    ┆ u32       ┆ u32  ┆ u32    ┆ u32       │\n",
      "╞════════╪═══════════╪══════╪════════╪═══════════╡\n",
      "│ 0      ┆ 0         ┆ 0    ┆ 0      ┆ 0         │\n",
      "└────────┴───────────┴──────┴────────┴───────────┘\n",
      "\n",
      "Unique values in Season after filling nulls:\n",
      "shape: (5,)\n",
      "Series: 'Season' [str]\n",
      "[\n",
      "\t\"KHARIF\"\n",
      "\t\"JAYAD\"\n",
      "\t\"RABI\"\n",
      "\t\"0\"\n",
      "\t\"Unspecified\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Define columns where nulls should be dropped\n",
    "columns_to_clean = [\n",
    "    'KccAns',\n",
    "    'QueryType',\n",
    "    'Crop',\n",
    "    'Sector',\n",
    "    'QueryText'\n",
    "]\n",
    "\n",
    "# Define columns where nulls should be filled with specific values\n",
    "fill_null_values = {\n",
    "    'Season': 'Unspecified'\n",
    "}\n",
    "\n",
    "# Run the analysis and cleaning\n",
    "cleaned_df, null_analysis = analyze_and_clean_nulls(\n",
    "    df=master_df,\n",
    "    columns_to_clean=columns_to_clean,\n",
    "    fill_nulls=fill_null_values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36267631, 11)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned_df\t master_df\t null_analysis\t \n"
     ]
    }
   ],
   "source": [
    "%who DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initial memory state:\n",
      "Current Memory Usage: 15596.65 MB (15.23 GB)\n",
      "\n",
      "Current Memory Usage: 15596.65 MB (15.23 GB)\n",
      "Available System Memory: 232.14 GB\n",
      "Memory Utilization: 7.5%\n"
     ]
    }
   ],
   "source": [
    "# Clear any existing DataFrames\n",
    "clear_memory(df_to_remove= [master_df, null_analysis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
