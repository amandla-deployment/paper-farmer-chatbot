{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "pl.Config.set_tbl_rows(1000)  # or whatever number of rows you want to see\n",
    "import pathlib\n",
    "import os\n",
    "import psutil\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_memory(df_to_remove=None):\n",
    "    \"\"\"Clear memory and print memory usage statistics\"\"\"\n",
    "    try:\n",
    "        # Print initial state\n",
    "        print(\"\\nInitial memory state:\")\n",
    "        process = psutil.Process(os.getpid())\n",
    "        initial_memory_mb = process.memory_info().rss / 1024 / 1024\n",
    "        print(f\"Current Memory Usage: {initial_memory_mb:.2f} MB ({initial_memory_mb/1024:.2f} GB)\")\n",
    "        \n",
    "        # Remove specific DataFrame if provided\n",
    "        if df_to_remove is not None:\n",
    "            if isinstance(df_to_remove, list):\n",
    "                # If a list of DataFrames is provided\n",
    "                for df in df_to_remove:\n",
    "                    del df\n",
    "            else:\n",
    "                # If a single DataFrame is provided\n",
    "                del df_to_remove\n",
    "        \n",
    "        # Force garbage collection\n",
    "        gc.collect()\n",
    "        \n",
    "        # Get new memory info\n",
    "        new_memory_mb = process.memory_info().rss / 1024 / 1024\n",
    "        memory_freed = initial_memory_mb - new_memory_mb\n",
    "        \n",
    "        print(f\"\\nCurrent Memory Usage: {new_memory_mb:.2f} MB ({new_memory_mb/1024:.2f} GB)\")\n",
    "        print(f\"Available System Memory: {psutil.virtual_memory().available / 1024 / 1024 / 1024:.2f} GB\")\n",
    "        print(f\"Memory Utilization: {psutil.virtual_memory().percent}%\")\n",
    "        \n",
    "        if memory_freed > 0:\n",
    "            print(f\"Memory freed: {memory_freed:.2f} MB\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Memory cleanup failed: {e}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to load and process the data\"\"\"\n",
    "    try:\n",
    "        print(\"Initial memory state:\")\n",
    "        clear_memory()\n",
    "        \n",
    "        print(\"\\nLoading CSV file...\")\n",
    "        # Read CSV with updated schema_overrides parameter\n",
    "        master_df = pl.read_csv('dataset/original_dataset/kcc_dataset.csv',\n",
    "            schema_overrides={\n",
    "                'Year': pl.Int32,\n",
    "                'Month': pl.Int32,\n",
    "                'Day': pl.Int32,\n",
    "                'Crop': pl.Utf8,\n",
    "                'DistrictName': pl.Utf8,\n",
    "                'QueryType': pl.Utf8,\n",
    "                'Season': pl.Utf8,\n",
    "                'Sector': pl.Utf8,\n",
    "                'StateName': pl.Utf8,\n",
    "                'QueryText': pl.Utf8,\n",
    "                'KccAns': pl.Utf8,\n",
    "                'Category': pl.Utf8,\n",
    "                'BlockName': pl.Utf8\n",
    "            },\n",
    "            low_memory=True\n",
    "        ).drop(['BlockName', 'Category'])\n",
    "        \n",
    "        print(\"\\nAfter loading CSV:\")\n",
    "        clear_memory()\n",
    "        \n",
    "        return master_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in data processing: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# First clear any existing DataFrames\n",
    "clear_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working on India level data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial memory state:\n",
      "\n",
      "Initial memory state:\n",
      "Current Memory Usage: 82.71 MB (0.08 GB)\n",
      "\n",
      "Current Memory Usage: 82.71 MB (0.08 GB)\n",
      "Available System Memory: 243.70 GB\n",
      "Memory Utilization: 2.9%\n",
      "\n",
      "Loading CSV file...\n",
      "\n",
      "After loading CSV:\n",
      "\n",
      "Initial memory state:\n",
      "Current Memory Usage: 11777.02 MB (11.50 GB)\n",
      "\n",
      "Current Memory Usage: 11777.02 MB (11.50 GB)\n",
      "Available System Memory: 232.26 GB\n",
      "Memory Utilization: 7.4%\n"
     ]
    }
   ],
   "source": [
    "# Usage examples:\n",
    "# Load the data\n",
    "master_df = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 11)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Year</th><th>Month</th><th>Day</th><th>Crop</th><th>DistrictName</th><th>QueryType</th><th>Season</th><th>Sector</th><th>StateName</th><th>QueryText</th><th>KccAns</th></tr><tr><td>i32</td><td>i32</td><td>i32</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>2006</td><td>1</td><td>17</td><td>&quot;1275&quot;</td><td>&quot;SAGAR&quot;</td><td>&quot;99&quot;</td><td>&quot;RABI&quot;</td><td>&quot;HORTICULTURE&quot;</td><td>&quot;MADHYA PRADESH&quot;</td><td>&quot;how to control flower drop in …</td><td>&quot;spray planofix4mlpump&quot;</td></tr><tr><td>2006</td><td>1</td><td>17</td><td>&quot;964&quot;</td><td>&quot;SAGAR&quot;</td><td>&quot;Disease Management&quot;</td><td>&quot;RABI&quot;</td><td>&quot;ANIMAL HUSBANDRY&quot;</td><td>&quot;MADHYA PRADESH&quot;</td><td>&quot;how tyo control diseases in bu…</td><td>null</td></tr><tr><td>2006</td><td>1</td><td>17</td><td>&quot;1279&quot;</td><td>&quot;SAGAR&quot;</td><td>&quot;76&quot;</td><td>&quot;RABI&quot;</td><td>&quot;HORTICULTURE&quot;</td><td>&quot;MADHYA PRADESH&quot;</td><td>&quot;how to control fruit borer in …</td><td>&quot;should be spray profenophos 35…</td></tr><tr><td>2006</td><td>1</td><td>17</td><td>&quot;1064&quot;</td><td>&quot;SAGAR&quot;</td><td>&quot;3&quot;</td><td>&quot;RABI&quot;</td><td>&quot;AGRICULTURE&quot;</td><td>&quot;MADHYA PRADESH&quot;</td><td>&quot;how to control of yellow moisa…</td><td>&quot;should be spray metasystox 35m…</td></tr><tr><td>2006</td><td>1</td><td>17</td><td>&quot;1279&quot;</td><td>&quot;DAMOH&quot;</td><td>&quot;76&quot;</td><td>&quot;RABI&quot;</td><td>&quot;HORTICULTURE&quot;</td><td>&quot;MADHYA PRADESH&quot;</td><td>&quot;how to control white fly in br…</td><td>&quot;should be spray metasystox 35m…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 11)\n",
       "┌──────┬───────┬─────┬──────┬───┬──────────────┬───────────┬───────────────────┬───────────────────┐\n",
       "│ Year ┆ Month ┆ Day ┆ Crop ┆ … ┆ Sector       ┆ StateName ┆ QueryText         ┆ KccAns            │\n",
       "│ ---  ┆ ---   ┆ --- ┆ ---  ┆   ┆ ---          ┆ ---       ┆ ---               ┆ ---               │\n",
       "│ i32  ┆ i32   ┆ i32 ┆ str  ┆   ┆ str          ┆ str       ┆ str               ┆ str               │\n",
       "╞══════╪═══════╪═════╪══════╪═══╪══════════════╪═══════════╪═══════════════════╪═══════════════════╡\n",
       "│ 2006 ┆ 1     ┆ 17  ┆ 1275 ┆ … ┆ HORTICULTURE ┆ MADHYA    ┆ how to control    ┆ spray             │\n",
       "│      ┆       ┆     ┆      ┆   ┆              ┆ PRADESH   ┆ flower drop in …  ┆ planofix4mlpump   │\n",
       "│ 2006 ┆ 1     ┆ 17  ┆ 964  ┆ … ┆ ANIMAL       ┆ MADHYA    ┆ how tyo control   ┆ null              │\n",
       "│      ┆       ┆     ┆      ┆   ┆ HUSBANDRY    ┆ PRADESH   ┆ diseases in bu…   ┆                   │\n",
       "│ 2006 ┆ 1     ┆ 17  ┆ 1279 ┆ … ┆ HORTICULTURE ┆ MADHYA    ┆ how to control    ┆ should be spray   │\n",
       "│      ┆       ┆     ┆      ┆   ┆              ┆ PRADESH   ┆ fruit borer in …  ┆ profenophos 35…   │\n",
       "│ 2006 ┆ 1     ┆ 17  ┆ 1064 ┆ … ┆ AGRICULTURE  ┆ MADHYA    ┆ how to control of ┆ should be spray   │\n",
       "│      ┆       ┆     ┆      ┆   ┆              ┆ PRADESH   ┆ yellow moisa…     ┆ metasystox 35m…   │\n",
       "│ 2006 ┆ 1     ┆ 17  ┆ 1279 ┆ … ┆ HORTICULTURE ┆ MADHYA    ┆ how to control    ┆ should be spray   │\n",
       "│      ┆       ┆     ┆      ┆   ┆              ┆ PRADESH   ┆ white fly in br…  ┆ metasystox 35m…   │\n",
       "└──────┴───────┴─────┴──────┴───┴──────────────┴───────────┴───────────────────┴───────────────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41987874, 11)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering: Null Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Null value analysis:\n",
      "shape: (11, 4)\n",
      "┌──────────────┬──────────────┬────────────┬─────────────────┐\n",
      "│ Column       ┆ Total_Values ┆ Null_Count ┆ Null_Percentage │\n",
      "│ ---          ┆ ---          ┆ ---        ┆ ---             │\n",
      "│ str          ┆ i32          ┆ i64        ┆ f64             │\n",
      "╞══════════════╪══════════════╪════════════╪═════════════════╡\n",
      "│ Season       ┆ 41987874     ┆ 26665089   ┆ 63.51           │\n",
      "│ KccAns       ┆ 41987874     ┆ 4320412    ┆ 10.29           │\n",
      "│ QueryType    ┆ 41987874     ┆ 1333503    ┆ 3.18            │\n",
      "│ Crop         ┆ 41987874     ┆ 172930     ┆ 0.41            │\n",
      "│ Sector       ┆ 41987874     ┆ 85083      ┆ 0.2             │\n",
      "│ QueryText    ┆ 41987874     ┆ 10560      ┆ 0.03            │\n",
      "│ Year         ┆ 41987874     ┆ 0          ┆ 0.0             │\n",
      "│ Month        ┆ 41987874     ┆ 0          ┆ 0.0             │\n",
      "│ Day          ┆ 41987874     ┆ 0          ┆ 0.0             │\n",
      "│ DistrictName ┆ 41987874     ┆ 0          ┆ 0.0             │\n",
      "│ StateName    ┆ 41987874     ┆ 0          ┆ 0.0             │\n",
      "└──────────────┴──────────────┴────────────┴─────────────────┘\n"
     ]
    }
   ],
   "source": [
    "total_rows = master_df.shape[0]\n",
    "\n",
    "# Create a DataFrame with both counts and percentages\n",
    "null_analysis = (\n",
    "    pl.DataFrame({\n",
    "        'Column': master_df.columns,\n",
    "        'Total_Values': total_rows,\n",
    "        'Null_Count': master_df.null_count().row(0),\n",
    "    })\n",
    "    .with_columns([\n",
    "        (pl.col('Null_Count') / pl.col('Total_Values') * 100).round(2).alias('Null_Percentage')\n",
    "    ])\n",
    "    .sort('Null_Percentage', descending=True)  # Sort by percentage descending\n",
    ")\n",
    "\n",
    "print(\"\\nNull value analysis:\")\n",
    "print(null_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (41987874, 11)\n",
      "Shape after removing nulls: (36267631, 11)\n"
     ]
    }
   ],
   "source": [
    "# First check the initial shape\n",
    "print(f\"Original shape: {master_df.shape}\")\n",
    "\n",
    "# List the specific columns you want to check for nulls\n",
    "columns_to_check = [\n",
    "    'KccAns',\n",
    "    'QueryType', \n",
    "    'Crop',\n",
    "    'Sector',\n",
    "    'QueryText']  # replace with your column names\n",
    "\n",
    "# Drop nulls only from specified columns\n",
    "master_df = master_df.drop_nulls(subset=columns_to_check)\n",
    "\n",
    "# Print new shape to see how many rows were removed\n",
    "print(f\"Shape after removing nulls: {master_df.shape}\")\n",
    "\n",
    "# # Optional: Check if there are any nulls remaining in these columns\n",
    "# null_check = master_df.select(columns_to_check).null_count()\n",
    "# print(\"\\nNull counts in specified columns after cleaning:\")\n",
    "# print(null_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5,)\n",
      "Series: 'Season' [str]\n",
      "[\n",
      "\t\"0\"\n",
      "\t\"RABI\"\n",
      "\t\"Unspecified\"\n",
      "\t\"KHARIF\"\n",
      "\t\"JAYAD\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Replace nulls in Season column with \"Unspecified\"\n",
    "master_df = master_df.with_columns(\n",
    "    pl.col('Season').fill_null(value=\"Unspecified\")\n",
    ")\n",
    "\n",
    "# Verify the replacement\n",
    "print(master_df['Season'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering: ONLY `digit` values in columns that are supposed to have texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Percentage of digit-only values in each column:\n",
      "shape: (11, 4)\n",
      "┌──────────────┬──────────────┬──────────────────┬────────────┐\n",
      "│ Column       ┆ Total_Values ┆ Digit_Only_Count ┆ Percentage │\n",
      "│ ---          ┆ ---          ┆ ---              ┆ ---        │\n",
      "│ str          ┆ i64          ┆ i64              ┆ f64        │\n",
      "╞══════════════╪══════════════╪══════════════════╪════════════╡\n",
      "│ Year         ┆ 36267631     ┆ 36267631         ┆ 100.0      │\n",
      "│ Month        ┆ 36267631     ┆ 36267631         ┆ 100.0      │\n",
      "│ Day          ┆ 36267631     ┆ 36267631         ┆ 100.0      │\n",
      "│ QueryType    ┆ 36267631     ┆ 2785401          ┆ 7.68       │\n",
      "│ Crop         ┆ 36267631     ┆ 1433408          ┆ 3.95       │\n",
      "│ Season       ┆ 36267631     ┆ 535174           ┆ 1.48       │\n",
      "│ Sector       ┆ 36267631     ┆ 298539           ┆ 0.82       │\n",
      "│ KccAns       ┆ 36267631     ┆ 41759            ┆ 0.12       │\n",
      "│ QueryText    ┆ 36267631     ┆ 2229             ┆ 0.01       │\n",
      "│ DistrictName ┆ 36267631     ┆ 0                ┆ 0.0        │\n",
      "│ StateName    ┆ 36267631     ┆ 0                ┆ 0.0        │\n",
      "└──────────────┴──────────────┴──────────────────┴────────────┘\n"
     ]
    }
   ],
   "source": [
    "def check_digit_only_percentages(df):\n",
    "    total_rows = df.shape[0]\n",
    "    results = []\n",
    "    \n",
    "    for col in df.columns:\n",
    "        # Count values that contain only digits using regex\n",
    "        digit_only_count = df.filter(\n",
    "            pl.col(col).cast(pl.Utf8).str.contains(r'^\\d+$')\n",
    "        ).height\n",
    "        \n",
    "        # Calculate percentage\n",
    "        percentage = (digit_only_count / total_rows * 100)\n",
    "        \n",
    "        results.append({\n",
    "            'Column': col,\n",
    "            'Total_Values': total_rows,\n",
    "            'Digit_Only_Count': digit_only_count,\n",
    "            'Percentage': round(percentage, 2)\n",
    "        })\n",
    "    \n",
    "    # Convert results to Polars DataFrame and sort by percentage\n",
    "    return (pl.DataFrame(results)\n",
    "            .sort('Percentage', descending=True))\n",
    "\n",
    "# Run the analysis\n",
    "digit_analysis = check_digit_only_percentages(master_df)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nPercentage of digit-only values in each column:\")\n",
    "print(digit_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New shape: (32724854, 11)\n"
     ]
    }
   ],
   "source": [
    "# List of columns to check\n",
    "columns_to_check = [\n",
    "    'QueryType', \n",
    "    'Crop',\n",
    "    'Season', \n",
    "    'Sector', \n",
    "    'KccAns',\n",
    "    'QueryText'\n",
    "    ]\n",
    "\n",
    "# First print original shape\n",
    "# print(f\"Original shape: {master_df.shape}\")\n",
    "\n",
    "# Create filter condition to remove rows with only digits in specified columns\n",
    "master_df = master_df.filter(\n",
    "    ~(pl.col(columns_to_check[0]).cast(pl.Utf8).str.contains(r'^\\d+$')) &\n",
    "    ~(pl.col(columns_to_check[1]).cast(pl.Utf8).str.contains(r'^\\d+$')) &\n",
    "    ~(pl.col(columns_to_check[2]).cast(pl.Utf8).str.contains(r'^\\d+$')) &\n",
    "    ~(pl.col(columns_to_check[3]).cast(pl.Utf8).str.contains(r'^\\d+$')) &\n",
    "    ~(pl.col(columns_to_check[4]).cast(pl.Utf8).str.contains(r'^\\d+$')) &\n",
    "    ~(pl.col(columns_to_check[5]).cast(pl.Utf8).str.contains(r'^\\d+$'))\n",
    ")\n",
    "\n",
    "# Print new shape\n",
    "print(f\"New shape: {master_df.shape}\")\n",
    "\n",
    "# Print how many rows were removed\n",
    "# rows_removed = master_df.shape[0] - filtered_master_df.shape[0]\n",
    "# print(f\"Rows removed: {rows_removed}\")\n",
    "\n",
    "# Optional: Verify by checking digit-only percentages in new DataFrame\n",
    "def check_digit_only_percentages(df, cols):\n",
    "    total_rows = df.shape[0]\n",
    "    results = []\n",
    "    \n",
    "    for col in cols:\n",
    "        digit_only_count = df.filter(\n",
    "            pl.col(col).cast(pl.Utf8).str.contains(r'^\\d+$')\n",
    "        ).height\n",
    "        \n",
    "        percentage = (digit_only_count / total_rows * 100)\n",
    "        \n",
    "        results.append({\n",
    "            'Column': col,\n",
    "            'Total_Values': total_rows,\n",
    "            'Digit_Only_Count': digit_only_count,\n",
    "            'Percentage': round(percentage, 2)\n",
    "        })\n",
    "    \n",
    "    return pl.DataFrame(results).sort('Percentage', descending=True)\n",
    "\n",
    "# Check percentages in new DataFrame\n",
    "# print(\"\\nPercentage of digit-only values in each column after filtering:\")\n",
    "# print(check_digit_only_percentages(master_df, columns_to_check))\n",
    "\n",
    "# Optionally clear old DataFrame from memory\n",
    "# clear_memory(df_to_remove=master_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = master_df.with_columns([\n",
    "    pl.concat_str([\n",
    "        pl.col('Day').cast(pl.Utf8).str.zfill(2),\n",
    "        pl.col('Month').cast(pl.Utf8).str.zfill(2),\n",
    "        pl.col('Year').cast(pl.Utf8)\n",
    "    ], separator='-')\n",
    "    .str.strptime(pl.Datetime, format='%d-%m-%Y')\n",
    "    .alias('Date')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 12)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Year</th><th>Month</th><th>Day</th><th>Crop</th><th>DistrictName</th><th>QueryType</th><th>Season</th><th>Sector</th><th>StateName</th><th>QueryText</th><th>KccAns</th><th>Date</th></tr><tr><td>i32</td><td>i32</td><td>i32</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>datetime[μs]</td></tr></thead><tbody><tr><td>2006</td><td>1</td><td>17</td><td>&quot;BovineCowBuffalo&quot;</td><td>&quot;INDORE&quot;</td><td>&quot;Dairy Production&quot;</td><td>&quot;RABI&quot;</td><td>&quot;ANIMAL HUSBANDRY&quot;</td><td>&quot;MADHYA PRADESH&quot;</td><td>&quot;How to increase milk productio…</td><td>&quot;you can give gylox powder 100 …</td><td>2006-01-17 00:00:00</td></tr><tr><td>2007</td><td>1</td><td>5</td><td>&quot;Coconut&quot;</td><td>&quot;SAMASTIPUR&quot;</td><td>&quot;Fertilizer Use and Availabilit…</td><td>&quot;KHARIF&quot;</td><td>&quot;HORTICULTURE&quot;</td><td>&quot;BIHAR&quot;</td><td>&quot;FERTILIZER DOSES OF COCONUT&quot;</td><td>&quot;FERTILIZER ARE NPK&nbsp;&nbsp;1:2:2 KGPL…</td><td>2007-01-05 00:00:00</td></tr><tr><td>2007</td><td>1</td><td>5</td><td>&quot;Others&quot;</td><td>&quot;KHAGARIA&quot;</td><td>&quot;Weather&quot;</td><td>&quot;KHARIF&quot;</td><td>&quot;AGRICULTURE&quot;</td><td>&quot;BIHAR&quot;</td><td>&quot;WEATHER CONDATION IN KHAGARIA&quot;</td><td>&quot;ANSWER GIVEN TO DETAIL &quot;</td><td>2007-01-05 00:00:00</td></tr><tr><td>2007</td><td>1</td><td>20</td><td>&quot;Others&quot;</td><td>&quot;KATIHAR&quot;</td><td>&quot;Weather&quot;</td><td>&quot;Unspecified&quot;</td><td>&quot;HORTICULTURE&quot;</td><td>&quot;BIHAR&quot;</td><td>&quot;Weather condition of Katihar d…</td><td>&quot;Answer given to farmer by Inte…</td><td>2007-01-20 00:00:00</td></tr><tr><td>2007</td><td>1</td><td>1</td><td>&quot;Onion&quot;</td><td>&quot;AHMADNAGAR&quot;</td><td>&quot;Agriculture Mechanization&quot;</td><td>&quot;Unspecified&quot;</td><td>&quot;HORTICULTURE&quot;</td><td>&quot;MAHARASHTRA&quot;</td><td>&quot;blight on onion&quot;</td><td>&quot;copper oxycloride25ml10lit of …</td><td>2007-01-01 00:00:00</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 12)\n",
       "┌──────┬───────┬─────┬──────────────┬───┬──────────────┬──────────────┬──────────────┬─────────────┐\n",
       "│ Year ┆ Month ┆ Day ┆ Crop         ┆ … ┆ StateName    ┆ QueryText    ┆ KccAns       ┆ Date        │\n",
       "│ ---  ┆ ---   ┆ --- ┆ ---          ┆   ┆ ---          ┆ ---          ┆ ---          ┆ ---         │\n",
       "│ i32  ┆ i32   ┆ i32 ┆ str          ┆   ┆ str          ┆ str          ┆ str          ┆ datetime[μs │\n",
       "│      ┆       ┆     ┆              ┆   ┆              ┆              ┆              ┆ ]           │\n",
       "╞══════╪═══════╪═════╪══════════════╪═══╪══════════════╪══════════════╪══════════════╪═════════════╡\n",
       "│ 2006 ┆ 1     ┆ 17  ┆ BovineCowBuf ┆ … ┆ MADHYA       ┆ How to       ┆ you can give ┆ 2006-01-17  │\n",
       "│      ┆       ┆     ┆ falo         ┆   ┆ PRADESH      ┆ increase     ┆ gylox powder ┆ 00:00:00    │\n",
       "│      ┆       ┆     ┆              ┆   ┆              ┆ milk         ┆ 100 …        ┆             │\n",
       "│      ┆       ┆     ┆              ┆   ┆              ┆ productio…   ┆              ┆             │\n",
       "│ 2007 ┆ 1     ┆ 5   ┆ Coconut      ┆ … ┆ BIHAR        ┆ FERTILIZER   ┆ FERTILIZER   ┆ 2007-01-05  │\n",
       "│      ┆       ┆     ┆              ┆   ┆              ┆ DOSES OF     ┆ ARE NPK      ┆ 00:00:00    │\n",
       "│      ┆       ┆     ┆              ┆   ┆              ┆ COCONUT      ┆ 1:2:2 KGPL…  ┆             │\n",
       "│ 2007 ┆ 1     ┆ 5   ┆ Others       ┆ … ┆ BIHAR        ┆ WEATHER      ┆ ANSWER GIVEN ┆ 2007-01-05  │\n",
       "│      ┆       ┆     ┆              ┆   ┆              ┆ CONDATION IN ┆ TO DETAIL    ┆ 00:00:00    │\n",
       "│      ┆       ┆     ┆              ┆   ┆              ┆ KHAGARIA     ┆              ┆             │\n",
       "│ 2007 ┆ 1     ┆ 20  ┆ Others       ┆ … ┆ BIHAR        ┆ Weather      ┆ Answer given ┆ 2007-01-20  │\n",
       "│      ┆       ┆     ┆              ┆   ┆              ┆ condition of ┆ to farmer by ┆ 00:00:00    │\n",
       "│      ┆       ┆     ┆              ┆   ┆              ┆ Katihar d…   ┆ Inte…        ┆             │\n",
       "│ 2007 ┆ 1     ┆ 1   ┆ Onion        ┆ … ┆ MAHARASHTRA  ┆ blight on    ┆ copper oxycl ┆ 2007-01-01  │\n",
       "│      ┆       ┆     ┆              ┆   ┆              ┆ onion        ┆ oride25ml10l ┆ 00:00:00    │\n",
       "│      ┆       ┆     ┆              ┆   ┆              ┆              ┆ it of …      ┆             │\n",
       "└──────┴───────┴─────┴──────────────┴───┴──────────────┴──────────────┴──────────────┴─────────────┘"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.write_csv(\n",
    "    \"dataset/processed_dataset/India_level_data_filtered.csv\",\n",
    "    separator=\",\",  # default is comma\n",
    "    include_header=True,  # include column names\n",
    "    null_value=\"\",  # how to represent null values\n",
    "    float_precision=3  # decimal places for float values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in /home/manimala/miniconda3/envs/rag/lib/python3.11/site-packages (19.0.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "pa.Table requires 'pyarrow' module to be installed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph_objects\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgo\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Get top 10 rows\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m top_10 \u001b[38;5;241m=\u001b[39m \u001b[43mall_India_QueryType\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhead\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Calculate the sum of percentages for remaining rows (Others)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m others_percentage \u001b[38;5;241m=\u001b[39m all_India_QueryType\u001b[38;5;241m.\u001b[39mslice(\u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpercentage\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/miniconda3/envs/rag/lib/python3.11/site-packages/polars/dataframe/frame.py:2435\u001b[0m, in \u001b[0;36mDataFrame.to_pandas\u001b[0;34m(self, use_pyarrow_extension_array, **kwargs)\u001b[0m\n\u001b[1;32m   2430\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Object \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtypes:\n\u001b[1;32m   2431\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_to_pandas_with_object_columns(\n\u001b[1;32m   2432\u001b[0m         use_pyarrow_extension_array\u001b[38;5;241m=\u001b[39muse_pyarrow_extension_array, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m   2433\u001b[0m     )\n\u001b[0;32m-> 2435\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_to_pandas_without_object_columns\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2436\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_pyarrow_extension_array\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_pyarrow_extension_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m   2437\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rag/lib/python3.11/site-packages/polars/dataframe/frame.py:2487\u001b[0m, in \u001b[0;36mDataFrame._to_pandas_without_object_columns\u001b[0;34m(self, df, use_pyarrow_extension_array, **kwargs)\u001b[0m\n\u001b[1;32m   2484\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[1;32m   2486\u001b[0m record_batches \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39m_df\u001b[38;5;241m.\u001b[39mto_pandas()\n\u001b[0;32m-> 2487\u001b[0m tbl \u001b[38;5;241m=\u001b[39m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTable\u001b[49m\u001b[38;5;241m.\u001b[39mfrom_batches(record_batches)\n\u001b[1;32m   2488\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_pyarrow_extension_array:\n\u001b[1;32m   2489\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tbl\u001b[38;5;241m.\u001b[39mto_pandas(\n\u001b[1;32m   2490\u001b[0m         self_destruct\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   2491\u001b[0m         split_blocks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   2492\u001b[0m         types_mapper\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m pa_dtype: pd\u001b[38;5;241m.\u001b[39mArrowDtype(pa_dtype),\n\u001b[1;32m   2493\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   2494\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/rag/lib/python3.11/site-packages/polars/dependencies.py:98\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     96\u001b[0m pfx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mod_pfx\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_module_name, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     97\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpfx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_module_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m module to be installed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: pa.Table requires 'pyarrow' module to be installed"
     ]
    }
   ],
   "source": [
    "all_India_QueryType = (master_df\n",
    "    .select(pl.col('QueryType'))\n",
    "    .group_by('QueryType')\n",
    "    .agg(pl.count('QueryType').alias('count'))\n",
    "    .with_columns([\n",
    "        (pl.col('count') / pl.col('count').sum() * 100).round(2).alias('percentage')\n",
    "    ])\n",
    "    .sort('count', descending=True)\n",
    ")\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Get top 10 rows\n",
    "top_10 = all_India_QueryType.head(10).to_pandas()\n",
    "\n",
    "# Calculate the sum of percentages for remaining rows (Others)\n",
    "others_percentage = all_India_QueryType.slice(10).select('percentage').sum().item()\n",
    "\n",
    "# Create labels and values for the chart\n",
    "labels = list(top_10['QueryType']) + ['Others']\n",
    "values = list(top_10['percentage']) + [others_percentage]\n",
    "\n",
    "# Create the donut chart\n",
    "fig = go.Figure(data=[go.Pie(\n",
    "    labels=labels,\n",
    "    values=values,\n",
    "    hole=0.4,\n",
    "    textinfo='label+percent',\n",
    "    textposition='outside',\n",
    "    showlegend=False,\n",
    "    direction='clockwise',\n",
    "    sort=False\n",
    ")])\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': 'Distribution of Query Types (Top 10)',\n",
    "        'y': 0.95,\n",
    "        'x': 0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'\n",
    "    },\n",
    "    width=1200,\n",
    "    height=800,\n",
    "    font=dict(size=14)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate counts and percentages by StateName and QueryType\n",
    "state_querytype_distribution = (master_df\n",
    "    .group_by(['StateName', 'QueryType'])\n",
    "    .agg(pl.count().alias('count'))\n",
    "    .with_columns([\n",
    "        pl.col('count').sum().over('StateName').alias('state_total')\n",
    "    ])\n",
    "    .with_columns([\n",
    "        (pl.col('count') / pl.col('state_total') * 100).round(2).alias('percentage')\n",
    "    ])\n",
    "    .sort(['StateName', 'count'], descending=[False, True])\n",
    ")\n",
    "\n",
    "# Display results\n",
    "print(\"\\nQueryType Distribution by State:\")\n",
    "print(state_querytype_distribution)\n",
    "\n",
    "# Optional: To see distribution for a specific state\n",
    "state_name = \"MAHARASHTRA\"  # replace with state you want to see\n",
    "state_distribution = state_querytype_distribution.filter(pl.col('StateName') == state_name)\n",
    "print(f\"\\nQueryType Distribution for {state_name}:\")\n",
    "print(state_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_type_stats = (master_df\n",
    "    .group_by('QueryType')\n",
    "    .agg(pl.count().alias('count'))\n",
    "    .with_columns([\n",
    "        (pl.col('count') / pl.col('count').sum() * 100).round(2).alias('percentage'),\n",
    "        pl.col('count').sum().alias('total')\n",
    "    ])\n",
    "    .sort('count', descending=True)\n",
    ")\n",
    "\n",
    "print(\"\\nQueryType Distribution:\")\n",
    "print(query_type_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_check = [\n",
    "    'Crop', \n",
    "    'DistrictName',\n",
    "    'QueryType', \n",
    "    'Season',\n",
    "    'Sector',\n",
    "    'StateName']\n",
    "conditions = [~pl.col(col).str.contains(r'\\d') for col in columns_to_check]\n",
    "master_df = master_df.filter(pl.all_horizontal(conditions))\n",
    "\n",
    "print(master_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(41987874 - 11553157)/41987874"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = master_df.filter(~pl.col('QueryType').str.contains(r'\\d'))\n",
    "print(master_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering: removing all numeric values from Crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = master_df.filter(~pl.col('Crop').str.contains(r'\\d'))\n",
    "print(master_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering: removing all numeric values from Sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = master_df.filter(~pl.col('Sector').str.contains(r'\\d'))\n",
    "print(master_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df['StateName'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using filter() method for Polars DataFrame\n",
    "maharashtra_df = master_df.filter(pl.col('StateName') == 'MAHARASHTRA')\n",
    "\n",
    "# Print shape to verify\n",
    "print(f\"Shape of maharashtra_df: {maharashtra_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_memory(df_to_remove=master_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILTER CONDITION: Filter master_df to keep only QueryType with string values\n",
    "maharashtra_df_stringQT = maharashtra_df.filter(~pl.col('QueryType').str.contains(r'\\d'))\n",
    "\n",
    "print(maharashtra_df_stringQT.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_memory(df_to_remove= maharashtra_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maharashtra_df_stringCrop = maharashtra_df_stringQT.filter(~pl.col('Crop').str.contains(r'\\d'))\n",
    "\n",
    "print(maharashtra_df_stringCrop.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_memory(df_to_remove= maharashtra_df_stringQT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maharashtra_df_stringCrop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_of_query = list(master_df['QueryType'].unique())\n",
    "\n",
    "# First remove None values\n",
    "valid_queries = [query for query in type_of_query if query is not None]\n",
    "\n",
    "# Then search for fertilizer/fertiliser\n",
    "fertilizer_queries = [query for query in valid_queries \n",
    "                     if 'fertilizer' in str(query).lower() or 'fertiliser' in str(query).lower()]\n",
    "\n",
    "# Print the matches\n",
    "print(\"Queries related to fertilizer/fertiliser:\")\n",
    "for query in fertilizer_queries:\n",
    "    print(f\"- {query}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use .filter() with pl.col('QueryType').is_in() to subset the DataFrame\n",
    "fertilizer_df = master_df.filter(pl.col('QueryType').is_in(fertilizer_queries))\n",
    "\n",
    "# Print the shape to verify\n",
    "print(f\"Shape of fertilizer_df: {fertilizer_df.shape}\")\n",
    "\n",
    "# Optional: Display unique QueryTypes in the filtered DataFrame to verify\n",
    "print(\"\\nUnique QueryTypes in fertilizer_df:\")\n",
    "print(fertilizer_df['QueryType'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILTER CONDITION: Filter master_df to keep only QueryType with string values\n",
    "master_df_filtered_QueryType = master_df.filter(~pl.col('QueryType').str.contains(r'\\d'))\n",
    "clear_memory(df_to_remove=master_df)  # Remove the original large DataFrame\n",
    "\n",
    "print(master_df_filtered_QueryType.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILTER CONDITION: Filter master_df to keep only QueryType with string values\n",
    "master_df_filtered_Crop = master_df_filtered_QueryType.filter(~pl.col('Crop').str.contains(r'\\d'))\n",
    "\n",
    "print(master_df_filtered_Crop.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_memory(df_to_remove=master_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_filtered_QueryType.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_filtered_QueryType['Crop'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = (master_df_filtered_QueryType\n",
    "    .select(pl.col('QueryType'))\n",
    "    .group_by('QueryType')\n",
    "    .agg(pl.count('QueryType').alias('count'))\n",
    "    .with_columns([\n",
    "        (pl.col('count') / pl.col('count').sum() * 100).round(2).alias('percentage')\n",
    "    ])\n",
    "    .sort('count', descending=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_memory():\n",
    "    \"\"\"Clear memory and print memory usage statistics\"\"\"\n",
    "    try:\n",
    "        # Force garbage collection\n",
    "        gc.collect()\n",
    "        \n",
    "        # Get current process\n",
    "        process = psutil.Process(os.getpid())\n",
    "        \n",
    "        # Get memory info\n",
    "        memory_mb = process.memory_info().rss / 1024 / 1024\n",
    "        \n",
    "        # Print memory info with more context\n",
    "        print(f\"\\nCurrent Memory Usage: {memory_mb:.2f} MB ({memory_mb/1024:.2f} GB)\")\n",
    "        print(f\"Available System Memory: {psutil.virtual_memory().available / 1024 / 1024 / 1024:.2f} GB\")\n",
    "        print(f\"Memory Utilization: {psutil.virtual_memory().percent}%\")\n",
    "        \n",
    "        # Force garbage collection again\n",
    "        gc.collect()\n",
    "        \n",
    "        # Get new memory info\n",
    "        new_memory_mb = process.memory_info().rss / 1024 / 1024\n",
    "        memory_freed = memory_mb - new_memory_mb\n",
    "        \n",
    "        if memory_freed > 0:\n",
    "            print(f\"Memory freed by garbage collection: {memory_freed:.2f} MB\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Memory cleanup failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the results\n",
    "result = (master_df_filtered_QueryType\n",
    "    .select(pl.col('QueryType'))\n",
    "    .group_by('QueryType')\n",
    "    .agg(pl.count('QueryType').alias('count'))\n",
    "    .with_columns([\n",
    "        (pl.col('count') / pl.col('count').sum() * 100).round(2).alias('percentage')\n",
    "    ])\n",
    "    .sort('count', descending=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Get top 10 rows\n",
    "top_10 = master_df_filtered_QueryType.head(10).to_pandas()\n",
    "\n",
    "# # Calculate the sum of percentages for remaining rows (Others)\n",
    "# others_percentage = master_df_filtered_QueryType.slice(10).select('percentage').sum().item()\n",
    "\n",
    "# # Create labels and values for the chart\n",
    "# labels = list(top_10['QueryType']) + ['Others']\n",
    "# values = list(top_10['percentage']) + [others_percentage]\n",
    "\n",
    "# # Create the donut chart\n",
    "# fig = go.Figure(data=[go.Pie(\n",
    "#     labels=labels,\n",
    "#     values=values,\n",
    "#     hole=0.4,\n",
    "#     textinfo='label+percent',\n",
    "#     textposition='outside',  # Changed from 'inside' to 'outside'\n",
    "#     showlegend=False,  # Changed to False to remove the legend\n",
    "#     direction='clockwise',\n",
    "#     sort=False\n",
    "# )])\n",
    "\n",
    "# # Update layout\n",
    "# fig.update_layout(\n",
    "#     title={\n",
    "#         'text': 'What Indian Farmers Query on',\n",
    "#         'y':0.95,\n",
    "#         'x':0.5,\n",
    "#         'xanchor': 'center',\n",
    "#         'yanchor': 'top'\n",
    "#     },\n",
    "#     width=1200,\n",
    "#     height=800,\n",
    "#     font=dict(size=14)\n",
    "# )\n",
    "\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_filtered_QueryType.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((master_df.shape[0] - master_df_filtered_QueryType.shape[0])/(master_df.shape[0]))*199"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_India_QueryType = (master_df\n",
    "    .select(pl.col('QueryType'))\n",
    "    # Add a filter to exclude QueryType containing numbers\n",
    "    .filter(~pl.col('QueryType').str.contains(r'\\d'))\n",
    "    .group_by('QueryType')\n",
    "    .agg(pl.count('QueryType').alias('count'))\n",
    "    .with_columns([\n",
    "        (pl.col('count') / pl.col('count').sum() * 100).round(2).alias('percentage')\n",
    "    ])\n",
    "    .sort('count', descending=True)\n",
    ")\n",
    "\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Get top 10 rows\n",
    "top_10 = all_India_QueryType.head(10).to_pandas()\n",
    "\n",
    "# Calculate the sum of percentages for remaining rows (Others)\n",
    "others_percentage = all_India_QueryType.slice(10).select('percentage').sum().item()\n",
    "\n",
    "# Create labels and values for the chart\n",
    "labels = list(top_10['QueryType']) + ['Others']\n",
    "values = list(top_10['percentage']) + [others_percentage]\n",
    "\n",
    "# Create the donut chart\n",
    "fig = go.Figure(data=[go.Pie(\n",
    "    labels=labels,\n",
    "    values=values,\n",
    "    hole=0.4,\n",
    "    textinfo='label+percent',\n",
    "    textposition='outside',  # Changed from 'inside' to 'outside'\n",
    "    showlegend=False,  # Changed to False to remove the legend\n",
    "    direction='clockwise',\n",
    "    sort=False\n",
    ")])\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': 'Distribution of Query Types (Top 10)',\n",
    "        'y':0.95,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'\n",
    "    },\n",
    "    width=1200,\n",
    "    height=800,\n",
    "    font=dict(size=14)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Get top 10 rows\n",
    "top_10 = all_India_QueryType.head(10).to_pandas()\n",
    "\n",
    "# Calculate the sum of percentages for remaining rows (Others)\n",
    "others_percentage = all_India_QueryType.slice(10).select('percentage').sum().item()\n",
    "\n",
    "# Create labels and values for the chart - multiply values by 100\n",
    "labels = list(top_10['QueryType']) + ['Others']\n",
    "values = [x * 100 for x in list(top_10['percentage'])] + [others_percentage * 100]\n",
    "\n",
    "# Create the donut chart\n",
    "fig = go.Figure(data=[go.Pie(\n",
    "    labels=labels, \n",
    "    values=values,\n",
    "    hole=0.4,\n",
    "    textinfo='label+percent',\n",
    "    textposition='inside',\n",
    "    texttemplate='%{label}<br>%{percent:.1f}%',\n",
    "    showlegend=True,\n",
    "    direction='clockwise',\n",
    "    sort=False,\n",
    "    pull=[0.1] + [0] * len(labels[1:])\n",
    ")])\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': 'Distribution of Query Types (Top 10)',\n",
    "        'y':0.95,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'\n",
    "    },\n",
    "    width=900,\n",
    "    height=700,\n",
    "    font=dict(size=12),\n",
    "    legend=dict(\n",
    "        orientation=\"h\",\n",
    "        yanchor=\"bottom\",\n",
    "        y=-0.1,\n",
    "        xanchor=\"center\",\n",
    "        x=0.5\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_India_QueryType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "# Import all required libraries\n",
    "import polars as pl\n",
    "import pathlib\n",
    "import os\n",
    "import psutil\n",
    "import gc\n",
    "\n",
    "def clear_memory():\n",
    "    \"\"\"Clear memory and print memory usage statistics\"\"\"\n",
    "    try:\n",
    "        # Force garbage collection\n",
    "        gc.collect()\n",
    "        \n",
    "        # Get current process\n",
    "        process = psutil.Process(os.getpid())\n",
    "        \n",
    "        # Get memory info\n",
    "        memory_mb = process.memory_info().rss / 1024 / 1024\n",
    "        \n",
    "        # Print memory info with more context\n",
    "        print(f\"\\nCurrent Memory Usage: {memory_mb:.2f} MB ({memory_mb/1024:.2f} GB)\")\n",
    "        print(f\"Available System Memory: {psutil.virtual_memory().available / 1024 / 1024 / 1024:.2f} GB\")\n",
    "        print(f\"Memory Utilization: {psutil.virtual_memory().percent}%\")\n",
    "            \n",
    "        # Force garbage collection again\n",
    "        gc.collect()\n",
    "        \n",
    "        # Get new memory info\n",
    "        new_memory_mb = process.memory_info().rss / 1024 / 1024\n",
    "        memory_freed = memory_mb - new_memory_mb\n",
    "        \n",
    "        if memory_freed > 0:\n",
    "            print(f\"Memory freed by garbage collection: {memory_freed:.2f} MB\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Memory cleanup failed: {e}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to load and process the data\"\"\"\n",
    "    try:\n",
    "        print(\"Initial memory state:\")\n",
    "        clear_memory()\n",
    "        \n",
    "        print(\"\\nLoading CSV file...\")\n",
    "        # Read CSV with updated schema_overrides parameter\n",
    "        master_df = pl.read_csv('dataset/original_dataset/kcc_dataset.csv',\n",
    "            schema_overrides={\n",
    "                'Year': pl.Int32,\n",
    "                'Month': pl.Int32,\n",
    "                'Day': pl.Int32,\n",
    "                'Crop': pl.Utf8,\n",
    "                'DistrictName': pl.Utf8,\n",
    "                'QueryType': pl.Utf8,\n",
    "                'Season': pl.Utf8,\n",
    "                'Sector': pl.Utf8,\n",
    "                'StateName': pl.Utf8,\n",
    "                'QueryText': pl.Utf8,\n",
    "                'KccAns': pl.Utf8,\n",
    "                'Category': pl.Utf8,\n",
    "                'BlockName': pl.Utf8\n",
    "            },\n",
    "            low_memory=True\n",
    "        ).drop(['BlockName', 'Category'])\n",
    "        \n",
    "        print(\"\\nAfter loading CSV:\")\n",
    "        clear_memory()\n",
    "        \n",
    "        return master_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in data processing: {e}\")\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    result_df = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df['QueryType']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_cropInsurance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Create a date column using pl.date\n",
    "master_df_cropInsurance = master_df_cropInsurance.with_columns([\n",
    "    pl.date(\n",
    "        year=pl.col('Year'),\n",
    "        month=pl.col('Month'),\n",
    "        day=1\n",
    "    ).alias('Date')\n",
    "])\n",
    "\n",
    "# Group by date and state, count occurrences\n",
    "monthly_state_counts = (\n",
    "    master_df_cropInsurance\n",
    "    .group_by(['Date', 'StateName'])\n",
    "    .agg(\n",
    "        pl.count().alias('count')\n",
    "    )\n",
    "    .sort('Date')\n",
    ")\n",
    "\n",
    "# Convert to pandas for easier plotting with plotly\n",
    "monthly_state_df = monthly_state_counts.to_pandas()\n",
    "\n",
    "# Create line plot\n",
    "fig = px.line(\n",
    "    monthly_state_df,\n",
    "    x='Date',\n",
    "    y='count',\n",
    "    color='StateName',\n",
    "    title='Crop Insurance Queries by State Over Time',\n",
    "    labels={\n",
    "        'Date': 'Month-Year',\n",
    "        'count': 'Number of Queries',\n",
    "        'StateName': 'State'\n",
    "    }\n",
    ")\n",
    "\n",
    "# Customize layout\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Month-Year\",\n",
    "    yaxis_title=\"Number of Queries\",\n",
    "    legend_title=\"State\",\n",
    "    hovermode='x unified',\n",
    "    template='plotly_white',\n",
    "    # Improve readability\n",
    "    xaxis=dict(\n",
    "        tickangle=45,\n",
    "        tickformat='%b %Y'\n",
    "    ),\n",
    "    # Add some margins for better display\n",
    "    margin=dict(t=50, b=100)\n",
    ")\n",
    "\n",
    "# Add hover data\n",
    "fig.update_traces(\n",
    "    hovertemplate='<b>%{y}</b> queries<br>%{x|%B %Y}<extra></extra>'\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n",
    "\n",
    "# Optional: Save the plot\n",
    "# fig.write_html(\"crop_insurance_queries.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb_no_weather = master_df.filter(\n",
    "    (pl.col('QueryType') != 'Weather') & \n",
    "    (~pl.col('QueryType').str.contains(r'^[0-9]+$'))\n",
    ")\n",
    "\n",
    "# Verify the results\n",
    "result = (master_df\n",
    "    .select(pl.col('QueryType'))\n",
    "    .group_by('QueryType')\n",
    "    .agg(pl.count('QueryType').alias('count'))\n",
    "    .with_columns([\n",
    "        (pl.col('count') / pl.col('count').sum() * 100).round(2).alias('percentage')\n",
    "    ])\n",
    "    .sort('count', descending=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df['QueryType'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_list = list(master_df['StateName'].unique())\n",
    "\n",
    "print(state_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb = master_df.filter(master_df['StateName'] == 'WEST BENGAL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "pl.Config.set_tbl_rows(100)  # or whatever number of rows you want to see\n",
    "\n",
    "# First, let's create a filter that identifies if a string is numeric\n",
    "wb_no_weather = master_df.filter(\n",
    "    (pl.col('QueryType') != 'Weather') & \n",
    "    (~pl.col('QueryType').str.contains(r'^[0-9]+$'))\n",
    ")\n",
    "\n",
    "# Verify the results\n",
    "result = (wb_no_weather\n",
    "    .select(pl.col('QueryType'))\n",
    "    .group_by('QueryType')\n",
    "    .agg(pl.count('QueryType').alias('count'))\n",
    "    .with_columns([\n",
    "        (pl.col('count') / pl.col('count').sum() * 100).round(2).alias('percentage')\n",
    "    ])\n",
    "    .sort('count', descending=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "pl.Config.set_tbl_rows(100)  # or whatever number of rows you want to see\n",
    "\n",
    "# Then run your query\n",
    "result = (wb_no_weather\n",
    " .select(pl.col('QueryType'))\n",
    " .group_by('QueryType')\n",
    " .agg(pl.count('QueryType').alias('count'))\n",
    " .with_columns([\n",
    "     (pl.col('count') / pl.col('count').sum() * 100).round(2).alias('percentage')\n",
    " ])\n",
    " .sort('count', descending=True))\n",
    "\n",
    "result  # Display the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(result['QueryType'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
