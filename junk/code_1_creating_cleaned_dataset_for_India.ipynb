{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl # type: ignore\n",
    "pl.Config.set_tbl_rows(1000)  # or whatever number of rows you want to see\n",
    "import psutil\n",
    "import os\n",
    "import gc\n",
    "from typing import Dict, Optional, Union, List\n",
    "from pathlib import Path\n",
    "# If you still have issues, try this alternative version using matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np # type: ignore\n",
    "import pandas as pd\n",
    "import squarify\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_memory(df_to_remove: Optional[Union[pl.DataFrame, List[pl.DataFrame]]] = None) -> None:\n",
    "    \"\"\"\n",
    "    Clear memory and print memory usage statistics\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Print initial state\n",
    "        print(\"\\nInitial memory state:\")\n",
    "        process = psutil.Process(os.getpid())\n",
    "        initial_memory_mb = process.memory_info().rss / 1024 / 1024\n",
    "        print(f\"Current Memory Usage: {initial_memory_mb:.2f} MB ({initial_memory_mb/1024:.2f} GB)\")\n",
    "        \n",
    "        # Remove specific DataFrame if provided\n",
    "        if df_to_remove is not None:\n",
    "            if isinstance(df_to_remove, list):\n",
    "                for df in df_to_remove:\n",
    "                    # Get the variable name\n",
    "                    name = [var_name for var_name, var_val in globals().items() if var_val is df]\n",
    "                    if name:\n",
    "                        globals().pop(name[0], None)\n",
    "                    del df\n",
    "            else:\n",
    "                name = [var_name for var_name, var_val in globals().items() if var_val is df_to_remove]\n",
    "                if name:\n",
    "                    globals().pop(name[0], None)\n",
    "                del df_to_remove\n",
    "                \n",
    "        # Force garbage collection\n",
    "        gc.collect()\n",
    "        \n",
    "        # Get new memory info\n",
    "        new_memory_mb = process.memory_info().rss / 1024 / 1024\n",
    "        memory_freed = initial_memory_mb - new_memory_mb\n",
    "        \n",
    "        print(f\"\\nCurrent Memory Usage: {new_memory_mb:.2f} MB ({new_memory_mb/1024:.2f} GB)\")\n",
    "        print(f\"Available System Memory: {psutil.virtual_memory().available / 1024 / 1024 / 1024:.2f} GB\")\n",
    "        print(f\"Memory Utilization: {psutil.virtual_memory().percent}%\")\n",
    "        \n",
    "        if memory_freed > 0:\n",
    "            print(f\"Memory freed: {memory_freed:.2f} MB\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Memory cleanup failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third cell - Define load_data function\n",
    "def load_data(\n",
    "    file_path: str,\n",
    "    schema_overrides: Optional[Dict] = None,\n",
    "    columns_to_drop: Optional[List[str]] = None,\n",
    "    low_memory: bool = True\n",
    ") -> Optional[pl.DataFrame]:\n",
    "    \"\"\"\n",
    "    Load and process a CSV file using Polars\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the CSV file\n",
    "        schema_overrides: Dictionary of column names and their data types\n",
    "        columns_to_drop: List of column names to drop\n",
    "        low_memory: Whether to use low memory mode\n",
    "    \n",
    "    Returns:\n",
    "        Processed Polars DataFrame or None if error occurs\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Ensure file exists\n",
    "        if not Path(file_path).exists():\n",
    "            raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "            \n",
    "        print(\"Initial memory state:\")\n",
    "        clear_memory()\n",
    "        \n",
    "        print(\"\\nLoading CSV file...\")\n",
    "        # Read CSV with provided schema overrides\n",
    "        df = pl.read_csv(\n",
    "            file_path,\n",
    "            schema_overrides=schema_overrides or {},\n",
    "            low_memory=low_memory\n",
    "        )\n",
    "        \n",
    "        # Drop specified columns if any\n",
    "        if columns_to_drop:\n",
    "            df = df.drop(columns_to_drop)\n",
    "            \n",
    "        print(\"\\nAfter loading CSV:\")\n",
    "        clear_memory()\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in data processing: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define schema overrides for your specific CSV\n",
    "schema = {\n",
    "    'Year': pl.Int32,\n",
    "    'Month': pl.Int32,\n",
    "    'Day': pl.Int32,\n",
    "    'Crop': pl.Utf8,\n",
    "    'DistrictName': pl.Utf8,\n",
    "    'QueryType': pl.Utf8,\n",
    "    'Season': pl.Utf8,\n",
    "    'Sector': pl.Utf8,\n",
    "    'StateName': pl.Utf8,\n",
    "    'QueryText': pl.Utf8,\n",
    "    'KccAns': pl.Utf8,\n",
    "    'Category': pl.Utf8,\n",
    "    'BlockName': pl.Utf8\n",
    "}\n",
    "\n",
    "# Specify columns to drop\n",
    "columns_to_drop = ['BlockName', 'Category']\n",
    "\n",
    "# Load your data (replace with your actual file path)\n",
    "master_df = load_data(\n",
    "    file_path='dataset/original_dataset/kcc_dataset.csv',  # Replace with your actual file path\n",
    "    schema_overrides=schema,\n",
    "    columns_to_drop=columns_to_drop,\n",
    "    low_memory=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Filtering: Null analysis and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_and_clean_nulls(\n",
    "    df: pl.DataFrame,\n",
    "    columns_to_clean: List[str],\n",
    "    fill_nulls: Dict[str, str] = None\n",
    ") -> tuple[pl.DataFrame, pl.DataFrame]:\n",
    "    \"\"\"\n",
    "    Analyze null values in a DataFrame and clean them according to specified rules.\n",
    "    \n",
    "    Args:\n",
    "        df: Input Polars DataFrame\n",
    "        columns_to_clean: List of column names where nulls should be dropped\n",
    "        fill_nulls: Dictionary of {column_name: fill_value} for replacing nulls\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (cleaned_df, null_analysis_df)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Store original shape for comparison\n",
    "        total_rows = df.shape[0]\n",
    "        print(f\"Original shape: {df.shape}\")\n",
    "        \n",
    "        # Create null value analysis DataFrame\n",
    "        null_analysis = (\n",
    "            pl.DataFrame({\n",
    "                'Column': df.columns,\n",
    "                'Total_Values': total_rows,\n",
    "                'Null_Count': df.null_count().row(0),\n",
    "            })\n",
    "            .with_columns([\n",
    "                # Calculate null percentage for each column\n",
    "                (pl.col('Null_Count') / pl.col('Total_Values') * 100)\n",
    "                .round(2)\n",
    "                .alias('Null_Percentage')\n",
    "            ])\n",
    "            .sort('Null_Percentage', descending=True)  # Sort by percentage descending\n",
    "        )\n",
    "        \n",
    "        print(\"\\nNull value analysis:\")\n",
    "        print(null_analysis)\n",
    "        \n",
    "        # Create a copy of the DataFrame for cleaning\n",
    "        cleaned_df = df.clone()\n",
    "        \n",
    "        # Drop nulls from specified columns\n",
    "        if columns_to_clean:\n",
    "            cleaned_df = cleaned_df.drop_nulls(subset=columns_to_clean)\n",
    "            print(f\"\\nShape after removing nulls: {cleaned_df.shape}\")\n",
    "            \n",
    "            # Optional: Verify null removal\n",
    "            null_check = cleaned_df.select(columns_to_clean).null_count()\n",
    "            print(\"\\nNull counts in specified columns after cleaning:\")\n",
    "            print(null_check)\n",
    "        \n",
    "        # Fill nulls in specified columns with provided values\n",
    "        if fill_nulls:\n",
    "            for column, fill_value in fill_nulls.items():\n",
    "                if column in cleaned_df.columns:\n",
    "                    cleaned_df = cleaned_df.with_columns(\n",
    "                        pl.col(column).fill_null(value=fill_value)\n",
    "                    )\n",
    "                    # Print unique values to verify replacement\n",
    "                    print(f\"\\nUnique values in {column} after filling nulls:\")\n",
    "                    print(cleaned_df[column].unique())\n",
    "                else:\n",
    "                    print(f\"\\nWarning: Column '{column}' not found in DataFrame\")\n",
    "        \n",
    "        return cleaned_df, null_analysis\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in analyze_and_clean_nulls: {e}\")\n",
    "        return df, None\n",
    "\n",
    "# Define columns where nulls should be dropped\n",
    "columns_to_clean = [\n",
    "    'KccAns',\n",
    "    'QueryType',\n",
    "    'Crop',\n",
    "    'Sector',\n",
    "    'QueryText'\n",
    "]\n",
    "\n",
    "# Define columns where nulls should be filled with specific values\n",
    "fill_null_values = {\n",
    "    'Season': 'Unspecified'\n",
    "}\n",
    "\n",
    "# Run the analysis and cleaning\n",
    "cleaned_df, null_analysis = analyze_and_clean_nulls(\n",
    "    df=master_df,\n",
    "    columns_to_clean=columns_to_clean,\n",
    "    fill_nulls=fill_null_values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear any existing DataFrames\n",
    "clear_memory(df_to_remove= [master_df, null_analysis])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering: ONLY `digit` values in columns that are supposed to have texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_digit_only_values(\n",
    "    df: pl.DataFrame,\n",
    "    columns_to_check: Optional[List[str]] = None,\n",
    "    remove_digit_only: bool = True\n",
    ") -> tuple[pl.DataFrame, pl.DataFrame, Dict]:\n",
    "    \"\"\"\n",
    "    Analyze and optionally remove rows containing only digits in specified columns.\n",
    "    \n",
    "    Args:\n",
    "        df: Input Polars DataFrame\n",
    "        columns_to_check: List of columns to analyze. If None, analyzes all columns\n",
    "        remove_digit_only: Whether to remove rows with digit-only values\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (cleaned_df, digit_analysis_df, stats_dict)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Initial statistics\n",
    "        initial_shape = df.shape\n",
    "        total_rows = initial_shape[0]\n",
    "        \n",
    "        # Use provided columns or all columns\n",
    "        cols_to_analyze = columns_to_check if columns_to_check else df.columns\n",
    "        \n",
    "        # Analyze digit-only values for all specified columns\n",
    "        results = []\n",
    "        for col in cols_to_analyze:\n",
    "            # Count values that contain only digits\n",
    "            digit_only_count = df.filter(\n",
    "                pl.col(col).cast(pl.Utf8).str.contains(r'^\\d+$')\n",
    "            ).height\n",
    "            \n",
    "            # Calculate percentage\n",
    "            percentage = (digit_only_count / total_rows * 100)\n",
    "            \n",
    "            results.append({\n",
    "                'Column': col,\n",
    "                'Total_Values': total_rows,\n",
    "                'Digit_Only_Count': digit_only_count,\n",
    "                'Percentage': round(percentage, 2)\n",
    "            })\n",
    "        \n",
    "        # Create analysis DataFrame\n",
    "        digit_analysis = pl.DataFrame(results).sort('Percentage', descending=True)\n",
    "        \n",
    "        # Print analysis results\n",
    "        print(\"\\nPercentage of digit-only values in each column:\")\n",
    "        print(digit_analysis)\n",
    "        \n",
    "        # Remove digit-only values if requested\n",
    "        if remove_digit_only and columns_to_check:\n",
    "            # Create filter conditions more efficiently\n",
    "            filter_conditions = [\n",
    "                ~pl.col(col).cast(pl.Utf8).str.contains(r'^\\d+$')\n",
    "                for col in columns_to_check\n",
    "            ]\n",
    "            \n",
    "            # Combine all conditions using reduce\n",
    "            from functools import reduce\n",
    "            import operator\n",
    "            \n",
    "            final_condition = reduce(operator.and_, filter_conditions)\n",
    "            \n",
    "            # Apply filter\n",
    "            cleaned_df = df.filter(final_condition)\n",
    "            \n",
    "            # Calculate statistics\n",
    "            final_shape = cleaned_df.shape\n",
    "            rows_removed = initial_shape[0] - final_shape[0]\n",
    "            \n",
    "            # Create stats dictionary\n",
    "            stats = {\n",
    "                'initial_rows': initial_shape[0],\n",
    "                'final_rows': final_shape[0],\n",
    "                'rows_removed': rows_removed,\n",
    "                'removal_percentage': round((rows_removed / initial_shape[0]) * 100, 2)\n",
    "            }\n",
    "            \n",
    "            # Print statistics\n",
    "            print(f\"\\nRows removed: {rows_removed:,} ({stats['removal_percentage']}%)\")\n",
    "            print(f\"Final shape: {final_shape}\")\n",
    "            \n",
    "            # Verify removal (optional)\n",
    "            verification = []\n",
    "            for col in columns_to_check:\n",
    "                digit_only_count = cleaned_df.filter(\n",
    "                    pl.col(col).cast(pl.Utf8).str.contains(r'^\\d+$')\n",
    "                ).height\n",
    "                verification.append({\n",
    "                    'Column': col,\n",
    "                    'Digit_Only_Count': digit_only_count,\n",
    "                    'Percentage': round((digit_only_count / final_shape[0]) * 100, 2)\n",
    "                })\n",
    "            \n",
    "            verification_df = pl.DataFrame(verification)\n",
    "            stats['verification'] = verification_df\n",
    "            \n",
    "        else:\n",
    "            cleaned_df = df\n",
    "            stats = {'message': 'No cleaning performed'}\n",
    "        \n",
    "        return cleaned_df, digit_analysis, stats\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in analyze_digit_only_values: {e}\")\n",
    "        return df, None, {'error': str(e)}\n",
    "    \n",
    "\n",
    "columns_to_check = [\n",
    "    'QueryType',\n",
    "    'Crop',\n",
    "    'Season',\n",
    "    'Sector',\n",
    "    'KccAns',\n",
    "    'QueryText'\n",
    "]\n",
    "\n",
    "# Run analysis and cleaning\n",
    "more_appropriate_df, analysis_df, stats = analyze_digit_only_values(\n",
    "    df=cleaned_df,\n",
    "    columns_to_check=columns_to_check,\n",
    "    remove_digit_only=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_appropriate_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = more_appropriate_df.with_columns([\n",
    "    pl.concat_str([\n",
    "        pl.col('Day').cast(pl.Utf8).str.zfill(2),\n",
    "        pl.col('Month').cast(pl.Utf8).str.zfill(2),\n",
    "        pl.col('Year').cast(pl.Utf8)\n",
    "    ], separator='-')\n",
    "    .str.strptime(pl.Datetime, format='%d-%m-%Y')\n",
    "    .alias('Date')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_memory(\n",
    "    df_to_remove= [\"analysis_df\",\t \n",
    "                   \"cleaned_df\",\n",
    "                   \"more_appropriate_df\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.write_csv(\n",
    "    \"dataset/processed_dataset/India_level_cleaned_data.csv\",\n",
    "    separator=\",\",           # Default is comma\n",
    "    include_header=True,        # Include column names\n",
    "    quote_char='\"',         # Quote character for strings\n",
    "    date_format=\"%Y-%m-%d\", # Format for date columns\n",
    "    float_precision=3       # Number of decimal places for floats\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_distribution_chart(\n",
    "    df: pl.DataFrame,\n",
    "    column: str,\n",
    "    top_n: int = 15,\n",
    "    title: str = None,\n",
    "    figsize: tuple = (14, 10),\n",
    "    colors: list = None,\n",
    "    font_sizes: dict = None,\n",
    "    donut_width: float = 0.6,\n",
    "    show_others: bool = True,\n",
    "    percentage_precision: int = 1\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a donut chart with flexible configuration options.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pl.DataFrame\n",
    "        Input DataFrame\n",
    "    column : str\n",
    "        Column name to analyze distribution\n",
    "    top_n : int, optional\n",
    "        Number of top categories to show (default: 15)\n",
    "    title : str, optional\n",
    "        Chart title (default: auto-generated based on column name)\n",
    "    figsize : tuple, optional\n",
    "        Figure size as (width, height) (default: (14, 10))\n",
    "    colors : list, optional\n",
    "        List of colors for the chart (default: predefined pastel colors)\n",
    "    font_sizes : dict, optional\n",
    "        Dictionary with font size configurations\n",
    "    donut_width : float, optional\n",
    "        Width of the donut (0 to 1) (default: 0.6)\n",
    "    show_others : bool, optional\n",
    "        Whether to group remaining categories as 'Others' (default: True)\n",
    "    percentage_precision : int, optional\n",
    "        Number of decimal places for percentage labels (default: 1)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        # Validate inputs\n",
    "        if column not in df.columns:\n",
    "            raise ValueError(f\"Column '{column}' not found in DataFrame\")\n",
    "            \n",
    "        # Set default font sizes if not provided\n",
    "        default_font_sizes = {\n",
    "            'title': 20,\n",
    "            'category_labels': 12,\n",
    "            'percentage_labels': 9\n",
    "        }\n",
    "        font_sizes = font_sizes or default_font_sizes\n",
    "        \n",
    "        # Set default colors if not provided\n",
    "        default_colors = [\n",
    "            '#FFB3BA',  # pastel pink\n",
    "            '#BAFFC9',  # pastel green\n",
    "            '#BAE1FF',  # pastel blue\n",
    "            '#FFFFBA',  # pastel yellow\n",
    "            '#FFB3FF',  # pastel purple\n",
    "            '#FFE4B5',  # pastel orange\n",
    "            '#E6E6FA',  # pastel lavender\n",
    "            '#98FB98',  # pale green\n",
    "            '#DDA0DD',  # plum\n",
    "            '#F0E68C',  # khaki\n",
    "            '#B0E0E6',  # powder blue\n",
    "            '#FFC0CB',  # pink\n",
    "            '#98FF98',  # mint\n",
    "            '#87CEEB',  # sky blue\n",
    "            '#DDA0DD'   # plum\n",
    "        ]\n",
    "        colors = colors or default_colors\n",
    "        \n",
    "        # Calculate distribution\n",
    "        distribution = (df\n",
    "            .select(pl.col(column))\n",
    "            .group_by(column)\n",
    "            .agg(pl.count(column).alias('count'))\n",
    "            .with_columns([\n",
    "                (pl.col('count') / pl.col('count').sum() * 100)\n",
    "                .round(2)\n",
    "                .alias('percentage')\n",
    "            ])\n",
    "            .sort('count', descending=True)\n",
    "        )\n",
    "        \n",
    "        # Get top categories and others\n",
    "        top_categories = distribution.head(top_n)\n",
    "        \n",
    "        if show_others and len(distribution) > top_n:\n",
    "            others_percentage = distribution.slice(top_n).select('percentage').sum().item()\n",
    "            labels = list(top_categories.get_column(column)) + ['Others']\n",
    "            values = list(top_categories.get_column('percentage')) + [others_percentage]\n",
    "        else:\n",
    "            labels = list(top_categories.get_column(column))\n",
    "            values = list(top_categories.get_column('percentage'))\n",
    "        \n",
    "        # Set up the plot\n",
    "        plt.figure(figsize=figsize, facecolor='white')\n",
    "        \n",
    "        # Create pie chart\n",
    "        patches, texts, autotexts = plt.pie(\n",
    "            values,\n",
    "            labels=labels,\n",
    "            autopct=f'%{percentage_precision}.{percentage_precision}f%%',\n",
    "            pctdistance=0.85,\n",
    "            wedgeprops=dict(\n",
    "                width=donut_width,\n",
    "                edgecolor='white',\n",
    "                linewidth=2\n",
    "            ),\n",
    "            colors=colors[:len(values)],\n",
    "            textprops={'fontsize': font_sizes['category_labels'], \n",
    "                      'fontweight': 'regular'}\n",
    "        )\n",
    "        \n",
    "        # Customize percentage labels\n",
    "        plt.setp(autotexts, \n",
    "                size=font_sizes['percentage_labels'], \n",
    "                weight=\"regular\", \n",
    "                color='black')\n",
    "        \n",
    "        # Customize category labels\n",
    "        plt.setp(texts, \n",
    "                size=font_sizes['category_labels'], \n",
    "                color='black')\n",
    "        \n",
    "        # Set title\n",
    "        # if title is None:\n",
    "        #     title = f'Distribution of {column}'\n",
    "        plt.title(title,\n",
    "                 pad=20,\n",
    "                 fontsize=font_sizes['title'],\n",
    "                 fontweight='bold',\n",
    "                 color='black')\n",
    "        \n",
    "        # Set background color\n",
    "        plt.gca().set_facecolor('white')\n",
    "        \n",
    "        # Adjust layout\n",
    "        plt.tight_layout()\n",
    "\n",
    "        plt.savefig('plots_folder/plot_1.png')\n",
    "        \n",
    "        # Show plot\n",
    "        plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating chart: {e}\")\n",
    "        import traceback\n",
    "        print(traceback.format_exc())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "# Basic usage:\n",
    "# create_distribution_chart(final_df, column='QueryType')\n",
    "\n",
    "# Advanced usage:\n",
    "create_distribution_chart(\n",
    "    df=final_df,\n",
    "    column='QueryType',\n",
    "    top_n=10,\n",
    "    # title='India-wide: Top Queries of Farmers',\n",
    "    figsize=(12, 12),\n",
    "    # colors=['#FFB3BA', '#BAFFC9', '#BAE1FF'],\n",
    "    font_sizes={\n",
    "        'title': 24,\n",
    "        'category_labels': 14,\n",
    "        'percentage_labels': 10\n",
    "    },\n",
    "    donut_width=0.7,\n",
    "    show_others=True,\n",
    "    percentage_precision=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution = (final_df\n",
    "        .select(pl.col(\"Crop\"))\n",
    "        .group_by(\"Crop\")\n",
    "        .agg(pl.count(\"Crop\").alias('count'))\n",
    "        .with_columns([\n",
    "            (pl.col('count') / pl.col('count').sum() * 100)\n",
    "            .round(2)\n",
    "            .alias('percentage')\n",
    "        ])\n",
    "        .sort('count', descending=True)\n",
    "    )\n",
    "\n",
    "top_categories = distribution.head(11)\n",
    "\n",
    "# Create a mapping for long names to shorter versions\n",
    "name_mapping = {\n",
    "    'Groundnut pea nutmung phalli': 'Groundnut',\n",
    "    'Bengal Gram GramChick PeaKabuliChana': 'Bengal Gram'\n",
    "}\n",
    "\n",
    "# Create a copy and update the names\n",
    "updated_categories = top_categories.clone()\n",
    "\n",
    "# Replace the long names with shorter versions\n",
    "for old_name, new_name in name_mapping.items():\n",
    "    updated_categories = updated_categories.with_columns(\n",
    "        pl.col(\"Crop\").replace(old_name, new_name)\n",
    "    )\n",
    "\n",
    "print(updated_categories)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_spectrum_radial_chart(data, exclude_first=True, figsize=(12, 12)):\n",
    "#     \"\"\"\n",
    "#     Create a radial bar chart with regulated text label angles.\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "        \n",
    "        \n",
    "#         # Convert to pandas if needed and exclude 'Others' if specified\n",
    "#         if not isinstance(data, pd.DataFrame):\n",
    "#             data = data.to_pandas()\n",
    "            \n",
    "#         if exclude_first:\n",
    "#             data = data.iloc[1:]\n",
    "            \n",
    "#         # Create spectrum colormap\n",
    "#         n_colors = len(data)\n",
    "#         colors = plt.cm.viridis(np.linspace(0, 1, n_colors))\n",
    "        \n",
    "#         # Create figure\n",
    "#         fig = plt.figure(figsize=figsize, facecolor='white')\n",
    "#         ax = fig.add_subplot(111, projection='polar')\n",
    "        \n",
    "#         # Calculate angles\n",
    "#         angles = np.linspace(0, 2*np.pi, len(data)+1)\n",
    "#         width = 2*np.pi / len(data)\n",
    "        \n",
    "#         # Create bars\n",
    "#         bars = ax.bar(\n",
    "#             angles[:-1],\n",
    "#             data['percentage'],\n",
    "#             width=width,\n",
    "#             bottom=20,  # Inner radius\n",
    "#             color=colors,\n",
    "#             alpha=0.9,\n",
    "#             edgecolor='white',\n",
    "#             linewidth=1\n",
    "#         )\n",
    "        \n",
    "#         def get_text_angle_and_alignment(angle):\n",
    "#             \"\"\"Calculate text angle and alignment based on position.\"\"\"\n",
    "#             # Convert to degrees for easier handling\n",
    "#             deg_angle = np.rad2deg(angle) % 360\n",
    "            \n",
    "#             # Right side of circle\n",
    "#             if deg_angle <= 90 or deg_angle >= 270:\n",
    "#                 text_angle = 0  # Horizontal text\n",
    "#                 ha = 'left'\n",
    "#                 if deg_angle <= 90:\n",
    "#                     va = 'bottom'\n",
    "#                 else:\n",
    "#                     va = 'top'\n",
    "#             # Left side of circle\n",
    "#             else:\n",
    "#                 text_angle = 360  # Horizontal text but flipped\n",
    "#                 ha = 'right'\n",
    "#                 if 90 < deg_angle <= 180:\n",
    "#                     va = 'bottom'\n",
    "#                 else:\n",
    "#                     va = 'top'\n",
    "            \n",
    "#             return text_angle, ha, va\n",
    "        \n",
    "#         # Add labels with connecting lines\n",
    "#         for angle, value, crop in zip(angles[:-1], data['percentage'], data['Crop']):\n",
    "#             # Calculate end point of bar\n",
    "#             bar_end = value + 25  # Add the bottom value\n",
    "            \n",
    "#             # Calculate label position\n",
    "#             text_radius = max(data['percentage']) + 15  # Use maximum value for consistent alignment\n",
    "            \n",
    "#             # Get text angle and alignment\n",
    "#             text_angle, ha, va = get_text_angle_and_alignment(angle)\n",
    "            \n",
    "#             # Calculate positions for the connecting line\n",
    "#             bar_end_x = np.cos(angle) * bar_end\n",
    "#             bar_end_y = np.sin(angle) * bar_end\n",
    "            \n",
    "#             # Add connecting line with bend\n",
    "#             line_radius = text_radius * 1.2\n",
    "#             ax.plot([angle, angle], [bar_end, line_radius], \n",
    "#                    color='gray', linewidth=0.5, alpha=0.5)\n",
    "            \n",
    "#             # Position for text\n",
    "#             text_x = np.cos(angle) * (line_radius * 1.1)\n",
    "#             text_y = np.sin(angle) * (line_radius * 1.1)\n",
    "            \n",
    "#             # Convert to display coordinates\n",
    "#             display_x = text_x\n",
    "#             display_y = text_y\n",
    "            \n",
    "#             # Add text with regulated angle\n",
    "#             ax.text(angle, line_radius * 1.1,\n",
    "#                    f'{crop}: {value:.1f}%',\n",
    "#                    ha=ha, \n",
    "#                    va=va,\n",
    "#                    rotation=text_angle,\n",
    "#                    rotation_mode='anchor',\n",
    "#                    fontsize = 16,\n",
    "#                    fontweight = 'regular')\n",
    "        \n",
    "#         # Customize the plot\n",
    "#         ax.set_frame_on(False)  # This removes the outer circle\n",
    "#         ax.set_theta_zero_location('N')\n",
    "#         ax.set_theta_direction(-1)\n",
    "        \n",
    "#         # Remove radial labels and axis lines\n",
    "#         ax.set_rticks([])\n",
    "#         ax.set_xticks([])\n",
    "#         ax.grid(False)\n",
    "        \n",
    "#         # Set limits to accommodate labels\n",
    "#         ax.set_rmax(text_radius * 1.4)\n",
    "        \n",
    "#         # plt.title('India-wide: Top 10 Crops that are of Concern ', pad=24, fontsize=24)\n",
    "#         plt.tight_layout()\n",
    "#         plt.savefig('plots_folder/plot_2.png')\n",
    "#         plt.show()\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"Error creating radial bar chart: {e}\")\n",
    "#         import traceback\n",
    "#         print(traceback.format_exc())\n",
    "\n",
    "# # Create the chart\n",
    "# create_spectrum_radial_chart(\n",
    "#     updated_categories,\n",
    "#     exclude_first=True,\n",
    "#     figsize=(12, 12)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_radial_bar_plot(data, exclude_first=True, figsize=(20, 10)):\n",
    "    try:\n",
    "        # Convert to pandas if needed and exclude 'Others' if specified\n",
    "        if not isinstance(data, pd.DataFrame):\n",
    "            data = data.to_pandas()\n",
    "            \n",
    "        if exclude_first:\n",
    "            data = data.iloc[1:]\n",
    "        \n",
    "        # Set figure size\n",
    "        plt.figure(figsize=figsize)\n",
    "        \n",
    "        # Create polar subplot\n",
    "        ax = plt.subplot(111, polar=True)\n",
    "        \n",
    "        # Remove grid and axis\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Set the coordinate limits\n",
    "        upperLimit = 100\n",
    "        lowerLimit = 30\n",
    "        \n",
    "        # Get max value and compute heights\n",
    "        max_value = data['percentage'].max()\n",
    "        slope = (upperLimit - lowerLimit) / max_value\n",
    "        heights = slope * data['percentage'] + lowerLimit\n",
    "        \n",
    "        # Compute width and angles\n",
    "        width = 2 * np.pi / len(data)\n",
    "        indexes = list(range(1, len(data) + 1))\n",
    "        angles = [element * width for element in indexes]\n",
    "        \n",
    "        # Create spectrum colormap\n",
    "        colors = plt.cm.viridis(np.linspace(0, 1, len(data)))\n",
    "        \n",
    "        # Draw bars\n",
    "        bars = ax.bar(\n",
    "            x=angles,\n",
    "            height=heights,\n",
    "            width=width * 0.8,\n",
    "            bottom=lowerLimit,\n",
    "            linewidth=2,\n",
    "            edgecolor=\"white\",\n",
    "            color=colors,\n",
    "            alpha=0.7\n",
    "        )\n",
    "        \n",
    "        # Add labels with fixed 45-degree angle\n",
    "        for angle, height, crop, value in zip(angles, heights, data['Crop'], data['percentage']):\n",
    "            # Calculate label position\n",
    "            label_radius = height + 10\n",
    "            \n",
    "            # Convert angle to degrees\n",
    "            deg_angle = np.rad2deg(angle)\n",
    "            \n",
    "            # Add label with fixed 45-degree rotation\n",
    "            plt.text(\n",
    "                angle, \n",
    "                label_radius,\n",
    "                f'{crop}: {value:.1f}%',\n",
    "                ha='left',\n",
    "                va='bottom',\n",
    "                rotation=00,  # Fixed 45-degree angle\n",
    "                rotation_mode='anchor',\n",
    "                fontsize=12,\n",
    "                fontweight='regular'\n",
    "            )\n",
    "        \n",
    "        # Set the direction of the zero angle\n",
    "        ax.set_theta_zero_location('N')\n",
    "        ax.set_theta_direction(-1)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('plots_folder/plot_2.png', bbox_inches='tight', dpi=1200)\n",
    "        plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating radial bar plot: {e}\")\n",
    "        import traceback\n",
    "        print(traceback.format_exc())\n",
    "\n",
    "# Create the chart\n",
    "create_radial_bar_plot(\n",
    "    updated_categories,\n",
    "    exclude_first=True,\n",
    "    figsize=(20, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_state_treemap(df: pl.DataFrame, threshold_pct: float = 1.0):\n",
    "\n",
    "    # Calculate state-wise distribution\n",
    "    distribution = (df\n",
    "        .select(pl.col('StateName'))\n",
    "        .group_by('StateName')\n",
    "        .agg(pl.len().alias('count'))\n",
    "        .sort('count', descending=True)\n",
    "    )\n",
    "    \n",
    "    # Calculate percentages\n",
    "    total = distribution['count'].sum()\n",
    "    distribution = distribution.with_columns([\n",
    "        (pl.col('count') / total * 100).alias('percentage')\n",
    "    ])\n",
    "    \n",
    "    # Round the percentage column\n",
    "    distribution = distribution.with_columns([\n",
    "        pl.col('percentage').round(1)\n",
    "    ])\n",
    "    \n",
    "    # Separate states into main states and others\n",
    "    main_states = distribution.filter(pl.col('percentage') >= threshold_pct)\n",
    "    other_states = distribution.filter(pl.col('percentage') < threshold_pct)\n",
    "    \n",
    "    # Calculate others total\n",
    "    others_total = other_states['count'].sum()\n",
    "    others_percentage = round((others_total / total * 100), 1)\n",
    "    \n",
    "    # Add others to main states if there are any states below threshold\n",
    "    if len(other_states) > 0:\n",
    "        # Create others row with same schema as main_states\n",
    "        others_row = pl.DataFrame({\n",
    "            'StateName': ['Others'],\n",
    "            'count': pl.Series([others_total], dtype=pl.UInt32),  # Explicitly set UInt32 type\n",
    "            'percentage': [others_percentage]\n",
    "        })\n",
    "        main_states = pl.concat([main_states, others_row])\n",
    "    \n",
    "    # Prepare data for plotting\n",
    "    values = main_states['count'].to_list()\n",
    "    states = main_states['StateName'].to_list()\n",
    "    percentages = main_states['percentage'].to_list()\n",
    "    \n",
    "    # Create labels\n",
    "    labels = [f\"{state}\\n{pct}%\" \n",
    "             for state, count, pct in zip(states, values, percentages)]\n",
    "    \n",
    "    # Create figure\n",
    "    plt.figure(figsize=(16, 12))\n",
    "    \n",
    "    # Define colors\n",
    "    colors = plt.cm.tab20b(np.linspace(0, 1, len(values)))\n",
    "    \n",
    "    # Create treemap\n",
    "    squarify.plot(\n",
    "        sizes=values,\n",
    "        label=labels,\n",
    "        color=colors,\n",
    "        alpha=0.8,\n",
    "        text_kwargs={\n",
    "            'fontsize': 16,\n",
    "            'fontweight': 'regular',\n",
    "            'color':'black'\n",
    "        },\n",
    "        pad=True\n",
    "    )\n",
    "    \n",
    "    # Customize the plot\n",
    "    plt.axis('off')\n",
    "    # plt.title('India-wide: Most Farmers Call from', \n",
    "    #             pad=20,\n",
    "    #             fontsize=24,\n",
    "    #             fontweight='bold',\n",
    "    #             color='black')\n",
    "\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"plots_folder/plot_3.png\")\n",
    "    plt.show()\n",
    "\n",
    "# Create the treemap with 1% threshold\n",
    "create_state_treemap(final_df, threshold_pct=2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def analyze_state_trends(df, n_states=5):\n",
    "    \"\"\"\n",
    "    Analyze and visualize yearly call trends for top N states.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : polars.DataFrame\n",
    "        Input dataframe with columns: Year, StateName\n",
    "    n_states : int, optional (default=10)\n",
    "        Number of top states to analyze\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    fig : matplotlib.figure.Figure\n",
    "        The generated plot figure\n",
    "    yearly_counts : polars.DataFrame\n",
    "        Processed data for top states\n",
    "    \"\"\"\n",
    "    # Get top N states by count\n",
    "    top_states = (df.group_by('StateName')\n",
    "                   .count()\n",
    "                   .sort('count', descending=True)\n",
    "                   .head(n_states)\n",
    "                   .get_column('StateName')\n",
    "                   .to_list())\n",
    "    \n",
    "    # Filter for top states\n",
    "    df_filtered = df.filter(pl.col('StateName').is_in(top_states))\n",
    "    \n",
    "    # Get yearly counts for each state\n",
    "    yearly_counts = (df_filtered.group_by(['Year', 'StateName'])\n",
    "                               .count()\n",
    "                               .pivot(\n",
    "                                   values='count',\n",
    "                                   index='Year',\n",
    "                                   columns='StateName'\n",
    "                               )\n",
    "                               .sort('Year'))\n",
    "    \n",
    "    # Create the visualization\n",
    "    plt.figure(figsize=(18, 8))\n",
    "    sns.set_style(\"white\")  # Clean style without gridlines\n",
    "\n",
    "    # Plot lines for each state\n",
    "    for state in top_states:\n",
    "        plt.plot(yearly_counts.get_column('Year'),\n",
    "                yearly_counts.get_column(state),\n",
    "                marker='o',\n",
    "                linewidth=2,\n",
    "                label=state)\n",
    "\n",
    "    # Customize the plot\n",
    "    plt.title(f'Top {n_states} states: Yearly Call Trends', pad=20, fontsize = 24, fontweight = 'bold')\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Number of Calls', fontsize = 16, fontweight = 'regular')\n",
    "    plt.xticks(yearly_counts.get_column('Year'))\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    # Format y-axis to use M notation\n",
    "    def format_func(x, p):\n",
    "        return f'{x/1000000:.1f}M'\n",
    "    plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(format_func))\n",
    "    plt.savefig('plots_folder/plot_4.png')\n",
    "    plt.tight_layout()\n",
    "        \n",
    "    return plt.gcf(), yearly_counts\n",
    "\n",
    "# Example usage:\n",
    "fig, data = analyze_state_trends(final_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # First get the top 10 states using len()\n",
    "top_states = (final_df.group_by('StateName')\n",
    "              .len()\n",
    "              .sort('len', descending=True)\n",
    "              .head(10)\n",
    "              .get_column('StateName')\n",
    "              .to_list())\n",
    "\n",
    "# Filter for top states, AGRICULTURE sector, and insurance-related queries\n",
    "govt_df = (final_df\n",
    "              .filter(pl.col('StateName').is_in(top_states))\n",
    "              .filter(pl.col('Sector') == 'AGRICULTURE')\n",
    "              .filter(pl.col('QueryType').str.to_lowercase().str.contains('schemes')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "govt_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_states = (final_df.group_by('StateName')\n",
    "#               .len()\n",
    "#               .sort('len', descending=True)\n",
    "#               .head(15)\n",
    "#               .get_column('StateName')\n",
    "#               .to_list())\n",
    "\n",
    "# agri_df = (final_df\n",
    "#               .filter(pl.col('StateName').is_in(top_states))\n",
    "#               .filter(pl.col('Sector') == 'AGRICULTURE')\n",
    "#             #   .filter(pl.col('QueryType').str.to_lowercase().str.contains('plant protection'))\n",
    "#               )\n",
    "\n",
    "# agri_df = (final_df\n",
    "#     .filter(pl.col('Sector') == 'AGRICULTURE')\n",
    "# )\n",
    "\n",
    "# First, let's calculate total counts and insurance counts per state\n",
    "# You might want to add more variations for government schemes\n",
    "state_percentages = (final_df\n",
    "    .group_by('StateName')\n",
    "    .agg([\n",
    "        pl.count().alias('total_queries'),\n",
    "        (\n",
    "            (pl.col('QueryType').str.to_lowercase().str.contains('insurance')) |\n",
    "            (pl.col('QueryType').str.to_lowercase().str.contains('government scheme')) |\n",
    "            (pl.col('QueryType').str.to_lowercase().str.contains('govt scheme')) |\n",
    "            (pl.col('QueryType').str.to_lowercase().str.contains('government schemes'))\n",
    "        ).sum().alias('insurance_govt_count')\n",
    "    ])\n",
    "    .with_columns([\n",
    "        (pl.col('insurance_govt_count') * 100 / pl.col('total_queries')).alias('insurance_govt_percentage')\n",
    "    ])\n",
    "    .sort('insurance_govt_percentage', descending=True)\n",
    ")\n",
    "\n",
    "\n",
    "# If you want just the StateName and percentage in a dictionary\n",
    "govt_scheme_or_insurance_by_state = dict(zip(\n",
    "    state_percentages.get_column('StateName').to_list(),\n",
    "    state_percentages.get_column('insurance_govt_percentage').round(2).to_list()\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "# Convert dictionary to DataFrame\n",
    "df = pd.DataFrame(list(govt_scheme_or_insurance_by_state.items()), \n",
    "                 columns=['State', 'Percentage'])\n",
    "\n",
    "# Create bar plot\n",
    "fig = px.bar(df, \n",
    "             x='State', \n",
    "             y='Percentage',\n",
    "            #  title='Insurance/Government Scheme Queries by State (%)',\n",
    "             labels={'Percentage': '(%) of Queries', \n",
    "                    'State': 'State Name'},\n",
    "             height=1000,\n",
    "             color='Percentage',  # Color bars by percentage\n",
    "             color_continuous_scale='Viridis')  # Use Viridis color scale\n",
    "\n",
    "# Customize layout\n",
    "fig.update_layout(\n",
    "    xaxis_tickangle=-90,  # Rotate x-axis labels\n",
    "    xaxis_title_font=dict(size=18),\n",
    "    yaxis_title_font=dict(size=18),\n",
    "    title_font=dict(size=16),\n",
    "    showlegend=False,\n",
    "    margin=dict(b=100)  # Add bottom margin for rotated labels\n",
    ")\n",
    "\n",
    "# Add hover template\n",
    "fig.update_traces(\n",
    "    hovertemplate=\"<br>\".join([\n",
    "        \"State: %{x}\",\n",
    "        \"Percentage: %{y:.2f}%\",\n",
    "        \"<extra></extra>\"\n",
    "    ])\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "govt_scheme_or_insurance_by_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate percentages for each state separately\n",
    "state_qt_percentages = {}\n",
    "\n",
    "for state in top_states:\n",
    "    # Filter for current state\n",
    "    state_df = agri_df.filter(pl.col('StateName') == state)\n",
    "    \n",
    "    # Get total count for this state\n",
    "    state_total = state_df.shape[0]\n",
    "    \n",
    "    # Calculate percentages for this state\n",
    "    state_percentages = (state_df\n",
    "        .group_by('QueryType')\n",
    "        .agg(\n",
    "            count=pl.count(),\n",
    "            percentage=(pl.count() * 100 / state_total)\n",
    "        )\n",
    "        .sort('count', descending=True)\n",
    "        .head(20)\n",
    "    )\n",
    "    \n",
    "    # Create dictionary for this state\n",
    "    state_qt_percentages = dict(zip(\n",
    "        state_percentages.get_column('QueryType').to_list(),\n",
    "        state_percentages.get_column('percentage').to_list()\n",
    "    ))\n",
    "    \n",
    "    # Add to main dictionary\n",
    "    state_qt_percentages[state] = state_qt_percentages\n",
    "\n",
    "# Now state_qt_percentages will be a nested dictionary:\n",
    "# {\n",
    "#     'State1': {'QueryType1': 25.5, 'QueryType2': 15.2, ...},\n",
    "#     'State2': {'QueryType1': 30.1, 'QueryType2': 12.8, ...},\n",
    "#     ...\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_qt_percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_QT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_state_trends(df, n_states=5):\n",
    "    # Get top N states by count\n",
    "    top_states = (df.group_by('StateName')\n",
    "                   .len()\n",
    "                   .sort('len', descending=True)\n",
    "                   .head(n_states)\n",
    "                   .get_column('StateName')\n",
    "                   .to_list())\n",
    "    \n",
    "    # Define dark pastel colors\n",
    "    colors = [\n",
    "        '#7B8FA1',  # dark pastel blue-gray\n",
    "        '#A4907C',  # dark pastel brown\n",
    "        '#917FB3',  # dark pastel purple\n",
    "        '#749F82',  # dark pastel green\n",
    "        '#A84448',  # dark pastel red\n",
    "    ]\n",
    "    \n",
    "    # Filter for top states\n",
    "    df_filtered = df.filter(pl.col('StateName').is_in(top_states))\n",
    "    \n",
    "    # Get yearly counts for each state\n",
    "    yearly_counts = (df_filtered.group_by(['Year', 'StateName'])\n",
    "                               .len()\n",
    "                               .pivot(\n",
    "                                   values='len',\n",
    "                                   index='Year',\n",
    "                                   columns='StateName'\n",
    "                               )\n",
    "                               .sort('Year'))\n",
    "    \n",
    "    # Create the visualization\n",
    "    plt.figure(figsize=(18, 8))\n",
    "    sns.set_style(\"white\")\n",
    "    \n",
    "    # Get years and data for plotting\n",
    "    years = yearly_counts.get_column('Year').to_numpy()  # Convert to numpy\n",
    "    bottom = np.zeros(len(years))\n",
    "    \n",
    "    # Create stacked bars\n",
    "    # for state in top_states:\n",
    "    #     values = yearly_counts.get_column(state).to_numpy()  # Convert to numpy\n",
    "    #     plt.bar(years, values, bottom=bottom, label=state)\n",
    "    #     bottom = bottom + values  # Changed from += to +\n",
    "\n",
    "    for i, state in enumerate(top_states):\n",
    "        values = yearly_counts.get_column(state).to_numpy()\n",
    "        plt.bar(years, values, bottom=bottom, label=state, color=colors[i])\n",
    "        bottom = bottom + values\n",
    "    \n",
    "    # Customize the plot\n",
    "    # plt.title(f'Top {n_states} states: Yearly trends in Crop Insurance related calls from Farmers', pad=20, fontsize=24, fontweight='bold')\n",
    "    plt.xlabel('Year', fontsize=16)\n",
    "    plt.ylabel('Number of Calls', fontsize=16, fontweight='regular')\n",
    "    plt.xticks(years)\n",
    "    plt.legend(bbox_to_anchor=(0.5, -0.25), loc='upper center', ncol=len(top_states), fontsize=16)\n",
    "    \n",
    "    # Format y-axis to use M notation\n",
    "    # def format_func(x, p):\n",
    "    #     return f'{x/1000000:.1f}M'\n",
    "    # plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(format_func))\n",
    "    \n",
    "    plt.savefig('plots_folder/plot_5.png', \n",
    "                bbox_inches='tight'\n",
    "                )\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return plt.gcf(), yearly_counts\n",
    "\n",
    "# Example usage:\n",
    "fig, data = analyze_state_trends(insurance_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
