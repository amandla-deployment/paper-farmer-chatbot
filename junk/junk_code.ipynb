{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/satyakama/Documents/paper-farmer-chatbot')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib as Path \n",
    "Path.Path.cwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6433/1370826671.py:5: DeprecationWarning: The argument `dtypes` for `read_csv` is deprecated. It has been renamed to `schema_overrides`.\n",
      "  df = pl.read_csv('dataset/original_dataset/kcc_dataset.csv',\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "try:\n",
    "    # Read CSV with explicit schema\n",
    "    df = pl.read_csv('dataset/original_dataset/kcc_dataset.csv',\n",
    "        dtypes={\n",
    "            'Year': pl.Int32,\n",
    "            'Month': pl.Int32,\n",
    "            'Day': pl.Int32,\n",
    "            'Crop': pl.Utf8,\n",
    "            'DistrictName': pl.Utf8,\n",
    "            'QueryType': pl.Utf8,\n",
    "            'Season': pl.Utf8,\n",
    "            'Sector': pl.Utf8,\n",
    "            'StateName': pl.Utf8,\n",
    "            'QueryText': pl.Utf8,\n",
    "            'KccAns': pl.Utf8,\n",
    "            'Category': pl.Utf8,\n",
    "            'BlockName': pl.Utf8\n",
    "        },\n",
    "        low_memory=True,\n",
    "        infer_schema_length=10000,\n",
    "        n_rows=1000  # Add this parameter to read only 1000 rows\n",
    "    ).drop(['BlockName', 'Category'])\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values in QueryText or KccAns\n",
    "df_clean = df.drop_nulls(subset=['QueryText', 'KccAns'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 11)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Year</th><th>Month</th><th>Day</th><th>Crop</th><th>DistrictName</th><th>QueryType</th><th>Season</th><th>Sector</th><th>StateName</th><th>QueryText</th><th>KccAns</th></tr><tr><td>i32</td><td>i32</td><td>i32</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>2006</td><td>1</td><td>17</td><td>&quot;1275&quot;</td><td>&quot;SAGAR&quot;</td><td>&quot;99&quot;</td><td>&quot;RABI&quot;</td><td>&quot;HORTICULTURE&quot;</td><td>&quot;MADHYA PRADESH&quot;</td><td>&quot;how to control flower drop in …</td><td>&quot;spray planofix4mlpump&quot;</td></tr><tr><td>2006</td><td>1</td><td>17</td><td>&quot;1279&quot;</td><td>&quot;SAGAR&quot;</td><td>&quot;76&quot;</td><td>&quot;RABI&quot;</td><td>&quot;HORTICULTURE&quot;</td><td>&quot;MADHYA PRADESH&quot;</td><td>&quot;how to control fruit borer in …</td><td>&quot;should be spray profenophos 35…</td></tr><tr><td>2006</td><td>1</td><td>17</td><td>&quot;1064&quot;</td><td>&quot;SAGAR&quot;</td><td>&quot;3&quot;</td><td>&quot;RABI&quot;</td><td>&quot;AGRICULTURE&quot;</td><td>&quot;MADHYA PRADESH&quot;</td><td>&quot;how to control of yellow moisa…</td><td>&quot;should be spray metasystox 35m…</td></tr><tr><td>2006</td><td>1</td><td>17</td><td>&quot;1279&quot;</td><td>&quot;DAMOH&quot;</td><td>&quot;76&quot;</td><td>&quot;RABI&quot;</td><td>&quot;HORTICULTURE&quot;</td><td>&quot;MADHYA PRADESH&quot;</td><td>&quot;how to control white fly in br…</td><td>&quot;should be spray metasystox 35m…</td></tr><tr><td>2006</td><td>1</td><td>17</td><td>&quot;Wheat&quot;</td><td>&quot;DAMOH&quot;</td><td>&quot;3&quot;</td><td>&quot;RABI&quot;</td><td>&quot;AGRICULTURE&quot;</td><td>&quot;MADHYA PRADESH&quot;</td><td>&quot;how to control termite in whea…</td><td>&quot;use chlorpyrephos1lithactwith …</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 11)\n",
       "┌──────┬───────┬─────┬───────┬───┬──────────────┬────────────────┬────────────────┬────────────────┐\n",
       "│ Year ┆ Month ┆ Day ┆ Crop  ┆ … ┆ Sector       ┆ StateName      ┆ QueryText      ┆ KccAns         │\n",
       "│ ---  ┆ ---   ┆ --- ┆ ---   ┆   ┆ ---          ┆ ---            ┆ ---            ┆ ---            │\n",
       "│ i32  ┆ i32   ┆ i32 ┆ str   ┆   ┆ str          ┆ str            ┆ str            ┆ str            │\n",
       "╞══════╪═══════╪═════╪═══════╪═══╪══════════════╪════════════════╪════════════════╪════════════════╡\n",
       "│ 2006 ┆ 1     ┆ 17  ┆ 1275  ┆ … ┆ HORTICULTURE ┆ MADHYA PRADESH ┆ how to control ┆ spray planofix │\n",
       "│      ┆       ┆     ┆       ┆   ┆              ┆                ┆ flower drop in ┆ 4mlpump        │\n",
       "│      ┆       ┆     ┆       ┆   ┆              ┆                ┆ …              ┆                │\n",
       "│ 2006 ┆ 1     ┆ 17  ┆ 1279  ┆ … ┆ HORTICULTURE ┆ MADHYA PRADESH ┆ how to control ┆ should be      │\n",
       "│      ┆       ┆     ┆       ┆   ┆              ┆                ┆ fruit borer in ┆ spray          │\n",
       "│      ┆       ┆     ┆       ┆   ┆              ┆                ┆ …              ┆ profenophos    │\n",
       "│      ┆       ┆     ┆       ┆   ┆              ┆                ┆                ┆ 35…            │\n",
       "│ 2006 ┆ 1     ┆ 17  ┆ 1064  ┆ … ┆ AGRICULTURE  ┆ MADHYA PRADESH ┆ how to control ┆ should be      │\n",
       "│      ┆       ┆     ┆       ┆   ┆              ┆                ┆ of yellow      ┆ spray          │\n",
       "│      ┆       ┆     ┆       ┆   ┆              ┆                ┆ moisa…         ┆ metasystox     │\n",
       "│      ┆       ┆     ┆       ┆   ┆              ┆                ┆                ┆ 35m…           │\n",
       "│ 2006 ┆ 1     ┆ 17  ┆ 1279  ┆ … ┆ HORTICULTURE ┆ MADHYA PRADESH ┆ how to control ┆ should be      │\n",
       "│      ┆       ┆     ┆       ┆   ┆              ┆                ┆ white fly in   ┆ spray          │\n",
       "│      ┆       ┆     ┆       ┆   ┆              ┆                ┆ br…            ┆ metasystox     │\n",
       "│      ┆       ┆     ┆       ┆   ┆              ┆                ┆                ┆ 35m…           │\n",
       "│ 2006 ┆ 1     ┆ 17  ┆ Wheat ┆ … ┆ AGRICULTURE  ┆ MADHYA PRADESH ┆ how to control ┆ use chlorpyrep │\n",
       "│      ┆       ┆     ┆       ┆   ┆              ┆                ┆ termite in     ┆ hos1lithactwit │\n",
       "│      ┆       ┆     ┆       ┆   ┆              ┆                ┆ whea…          ┆ h …            │\n",
       "└──────┴───────┴─────┴───────┴───┴──────────────┴────────────────┴────────────────┴────────────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RECOMMENDED VARIETIES ARE MORDENDRSF-108DRSH-1'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean['KccAns'][540]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/satyakama/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/satyakama/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /home/satyakama/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to /home/satyakama/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/satyakama/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "nltk.download('punkt')\n",
    "from nltk import word_tokenize, ne_chunk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input: RECOMMENDED TO SPRAY DIMETHOATE 2MLLIT\n",
      "Parsed: {'chemical/medicine': None, 'dosage': None}\n",
      "\n",
      "Input: RECOMMENDED VARIETIES ARE MORDENDRSF-108DRSH-1\n",
      "Parsed: {'chemical/medicine': None, 'dosage': None}\n",
      "\n",
      "Input: should be spray metasystox 35mL\n",
      "Parsed: {'chemical/medicine': None, 'dosage': None}\n",
      "\n",
      "Input: spray planofix4mlpump\n",
      "Parsed: {'chemical/medicine': None, 'dosage': None}\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "import re\n",
    "\n",
    "def parse_agricultural_recommendation(text):\n",
    "    \"\"\"Parse agricultural recommendation text to extract chemical and dosage information\"\"\"\n",
    "    # Ask Mistral to help structure the information\n",
    "    prompt = f\"\"\"\n",
    "    Parse this agricultural recommendation and extract the chemical/medicine name and dosage:\n",
    "    \"{text}\"\n",
    "    Return only a Python dictionary with keys 'chemical/medicine' and 'dosage'. \n",
    "    If it's about varieties, use 'variety' as the key instead.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = ollama.generate(\n",
    "        model='mistral',\n",
    "        prompt=prompt,\n",
    "        # temperature=0.1  # Lower temperature for more consistent outputs\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # Clean up the response to get just the dictionary part\n",
    "        # The model should return something like \"{'chemical/medicine': 'dimethoate', 'dosage': '2mL'}\"\n",
    "        response_text = response['response']\n",
    "        # Use regex to extract the dictionary-like structure\n",
    "        dict_match = re.search(r'\\{.*\\}', response_text)\n",
    "        if dict_match:\n",
    "            # Safely evaluate the dictionary string\n",
    "            result = eval(dict_match.group())\n",
    "            return result\n",
    "        else:\n",
    "            return {'chemical/medicine': None, 'dosage': None}\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing response for text '{text}': {e}\")\n",
    "        return {'chemical/medicine': None, 'dosage': None}\n",
    "\n",
    "# Define your list of input texts\n",
    "inputs = [\n",
    "    \"RECOMMENDED TO SPRAY DIMETHOATE 2MLLIT\",\n",
    "    \"RECOMMENDED VARIETIES ARE MORDENDRSF-108DRSH-1\",\n",
    "    \"should be spray metasystox 35mL\",\n",
    "    \"spray planofix4mlpump\"\n",
    "]\n",
    "\n",
    "# Process each input\n",
    "parsed_results = []\n",
    "for text in inputs:\n",
    "    result = parse_agricultural_recommendation(text)\n",
    "    parsed_results.append(result)\n",
    "\n",
    "# Print the results\n",
    "for input_text, result in zip(inputs, parsed_results):\n",
    "    print(f\"\\nInput: {input_text}\")\n",
    "    print(f\"Parsed: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b4c732a591340eb8c1d88abf27a83fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/849 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e6c6596bf5b4d72b30bb657f3b242fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ae447dc8e264e999452eb66e0c9175c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/255 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "334dcdb0796f4016b12717198ebf7be9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0739bdfef311451299580fdd89d5964e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45ac564bd4a642a1b55b5ede10ff3256",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input: RECOMMENDED TO SPRAY DIMETHOATE 2MLLIT\n",
      "Extracted: {'chemical/medicine': 'Dimethoate', 'dosage': '2ML'}\n",
      "\n",
      "Input: RECOMMENDED VARIETIES ARE MORDENDRSF-108DRSH-1\n",
      "Extracted: {'chemical/medicine': None, 'dosage': None}\n",
      "\n",
      "Input: should be spray metasystox 35mL\n",
      "Extracted: {'chemical/medicine': 'Metasystox', 'dosage': '35mL'}\n",
      "\n",
      "Input: spray planofix4mlpump\n",
      "Extracted: {'chemical/medicine': 'Planofix', 'dosage': '4ml'}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import re\n",
    "from typing import Dict, Optional, List\n",
    "\n",
    "class ChemicalDosageExtractor:\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the NER pipeline and compile regex patterns\"\"\"\n",
    "        # Load the NER pipeline\n",
    "        self.ner = pipeline(\"ner\", model=\"Jean-Baptiste/roberta-large-ner-english\")\n",
    "        \n",
    "        # Compile regex patterns\n",
    "        self.dosage_pattern = re.compile(r'(\\d+(?:\\.\\d+)?)\\s*(?:ML|MLLIT|MLPUMP|ML/LIT)', re.IGNORECASE)\n",
    "        \n",
    "        # Common chemical/pesticide names to check\n",
    "        self.common_chemicals = {\n",
    "            'DIMETHOATE', 'METASYSTOX', 'PLANOFIX'\n",
    "        }\n",
    "\n",
    "    def extract_from_text(self, text: str) -> Dict[str, Optional[str]]:\n",
    "        \"\"\"\n",
    "        Extract chemical names and dosages from text\n",
    "        \n",
    "        Args:\n",
    "            text: Input text containing chemical and dosage information\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with chemical name and dosage\n",
    "        \"\"\"\n",
    "        # First try to find common chemicals\n",
    "        chemical = None\n",
    "        for chem in self.common_chemicals:\n",
    "            if chem in text.upper():\n",
    "                chemical = chem.capitalize()\n",
    "                break\n",
    "        \n",
    "        # If no common chemical found, try NER\n",
    "        if not chemical:\n",
    "            entities = self.ner(text)\n",
    "            for entity in entities:\n",
    "                if entity['entity'] in ['B-ORG', 'I-ORG', 'B-MISC', 'I-MISC']:\n",
    "                    chemical = entity['word']\n",
    "                    break\n",
    "        \n",
    "        # Extract dosage using regex\n",
    "        dosage_match = self.dosage_pattern.search(text)\n",
    "        dosage = dosage_match.group(0) if dosage_match else None\n",
    "        \n",
    "        return {\n",
    "            \"chemical/medicine\": chemical,\n",
    "            \"dosage\": dosage\n",
    "        }\n",
    "\n",
    "    def process_texts(self, texts: List[str]) -> List[Dict[str, Optional[str]]]:\n",
    "        \"\"\"\n",
    "        Process multiple texts\n",
    "        \n",
    "        Args:\n",
    "            texts: List of input texts\n",
    "            \n",
    "        Returns:\n",
    "            List of dictionaries containing extracted information\n",
    "        \"\"\"\n",
    "        return [self.extract_from_text(text) for text in texts]\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize the extractor\n",
    "    extractor = ChemicalDosageExtractor()\n",
    "    \n",
    "    # Example inputs\n",
    "    inputs = [\n",
    "        \"RECOMMENDED TO SPRAY DIMETHOATE 2MLLIT\",\n",
    "        \"RECOMMENDED VARIETIES ARE MORDENDRSF-108DRSH-1\",\n",
    "        \"should be spray metasystox 35mL\",\n",
    "        \"spray planofix4mlpump\"\n",
    "    ]\n",
    "    \n",
    "    # Process texts\n",
    "    results = extractor.process_texts(inputs)\n",
    "    \n",
    "    # Print results\n",
    "    for text, result in zip(inputs, results):\n",
    "        print(f\"\\nInput: {text}\")\n",
    "        print(f\"Extracted: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print info about both dataframes\n",
    "print(\"=\"*50)\n",
    "print(\"\\nOriginal DataFrame Info:\")\n",
    "print(f\"Number of rows: {len(df):,}\")\n",
    "print(f\"Memory usage: {df.estimated_size() / (1024**3):.2f} GB\")\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"\\nUnimportant columns dropped DataFrame Info:\")\n",
    "print(f\"Number of rows: {len(df_clean):,}\")\n",
    "print(f\"Memory usage: {df_clean.estimated_size() / (1024**3):.2f} GB\")\n",
    "print(f\"Rows removed: {len(df) - len(df_clean):,}\")\n",
    "print(f\"Time taken: {time.time() - start:.2f} seconds\")\n",
    "print(\"Columns:\", df_clean.columns)\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get value counts for KccAns\n",
    "top_answers_KccAns = (\n",
    "    df_clean\n",
    "    .select(pl.col('KccAns'))\n",
    "    .group_by('KccAns')\n",
    "    .count()\n",
    "    .sort('count', descending=True)\n",
    "    .limit(15)\n",
    ")\n",
    "\n",
    "print(\"\\nTop 15 most frequent answers in KccAns:\")\n",
    "print(\"=======================================\")\n",
    "total_rows = len(df_clean)\n",
    "for row in top_answers_KccAns.iter_rows():\n",
    "    answer, count = row\n",
    "    percentage = (count / total_rows) * 100\n",
    "    print(f\"\\nCount: {count:,} ({percentage:.2f}%)\")\n",
    "    print(f\"Answer: {answer[:200]}...\")\n",
    "\n",
    "    # # Get value counts for QueryText\n",
    "    # top_answers_QueryText = (\n",
    "    #     df_clean\n",
    "    #     .select(pl.col('QueryText'))\n",
    "    #     .group_by('QueryText')\n",
    "    #     .count()\n",
    "    #     .sort('count', descending=True)\n",
    "    #     .limit(10)\n",
    "    # )\n",
    "\n",
    "    # print(\"\\nTop 10 most frequent answers in QueryText:\")\n",
    "    # print(\"=======================================\")\n",
    "    # total_rows = len(df_clean)\n",
    "    # for row in top_answers_QueryText.iter_rows():\n",
    "    #     answer, count = row\n",
    "    #     percentage = (count / total_rows) * 100\n",
    "    #     print(f\"\\nCount: {count:,} ({percentage:.2f}%)\")\n",
    "    #     print(f\"Answer: {answer[:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = dd.read_csv('kcc_dataset.csv', dtype='object') \n",
    "\n",
    "print(f'Column names: {master_df.columns}')\n",
    "\n",
    "print(f'Original number of rows in masters_df: {len(master_df.compute())}')\n",
    "\n",
    "cleaned_df_completeKccAns = master_df.dropna(subset=['KccAns'])\n",
    "\n",
    "print(f'Original number of rows in cleaned_df_completeKccAns: {len(cleaned_df_completeKccAns.compute())}')\n",
    "\n",
    "# Drop all rows in which KccAns is NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out rows containing 'Call Disconnected'\n",
    "cleaned_df_completeKccAns_dropCallDisconnected = cleaned_df_completeKccAns[\n",
    "    ~(cleaned_df_completeKccAns['QueryText'].str.contains('Call Disconnected', case=False, na=False)) &\n",
    "    ~(cleaned_df_completeKccAns['KccAns'].str.contains('Call Disconnected', case=False, na=False))\n",
    "]\n",
    "\n",
    "# Check the row counts\n",
    "original_count = len(cleaned_df_completeKccAns.compute())\n",
    "new_count = len(cleaned_df_completeKccAns_dropCallDisconnected.compute())\n",
    "\n",
    "print(f'Number of rows before filtering: {original_count}')\n",
    "print(f'Number of rows after filtering: {new_count}')\n",
    "print(f'Number of rows removed: {original_count - new_count}')\n",
    "print(f'Percentage of rows removed: {((original_count - new_count) / original_count * 100):.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative approach\n",
    "try:\n",
    "    # First materialize the column as a series\n",
    "    query_series = cleaned_df_completeKccAns_dropCallDisconnected['QueryText'].astype(str)  # ensure string type\n",
    "    \n",
    "    # Then get value counts\n",
    "    top_queries = query_series.value_counts().nlargest(10).compute()\n",
    "    \n",
    "    print(\"\\nTop 10 most frequent queries:\")\n",
    "    for query, count in top_queries.items():\n",
    "        print(f\"Count: {count}, Query: {query}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df_completeKccAns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = dd.read_csv('kcc_dataset.csv', dtype='object') \n",
    "\n",
    "print(f'Column names: {master_df.columns}')\n",
    "\n",
    "\n",
    "# Calculate the percentage of NaN values\n",
    "nan_percentage_kccAns = (master_df['KccAns'].isna().sum() / len(master_df) * 100).compute()\n",
    "\n",
    "print(f'Percentage of NaN values in KccAns: {nan_percentage_kccAns:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop column names\n",
    "master_df = master_df.drop(columns=['BlockName', 'Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count rows where any column has NaN\n",
    "rows_with_nan = master_df.isna().any(axis=1).sum().compute()\n",
    "\n",
    "# Get total number of rows\n",
    "total_rows = len(master_df.compute())\n",
    "\n",
    "# Calculate percentage\n",
    "nan_percentage = (rows_with_nan / total_rows) * 100\n",
    "\n",
    "print(f'Total number of rows: {total_rows}')\n",
    "print(f'Number of rows with at least one NaN: {rows_with_nan}')\n",
    "print(f'Percentage of rows with at least one NaN: {nan_percentage:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get NaN count for each column\n",
    "column_nan_counts = master_df.isna().sum().compute()\n",
    "column_nan_percentages = (column_nan_counts / total_rows * 100)\n",
    "\n",
    "print(\"\\nNaN distribution by column:\")\n",
    "for column in master_df.columns:\n",
    "    count = column_nan_counts[column]\n",
    "    percentage = column_nan_percentages[column]\n",
    "    print(f'{column}: {count} NaN values ({percentage:.2f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import dask.dataframe as dd\n",
    "\n",
    "import os\n",
    "import tqdm as tqdm\n",
    "\n",
    "\n",
    "# Reading all columns as strings\n",
    "master_df = dd.read_csv('kcc_dataset.csv', dtype='object') \n",
    "\n",
    "print(master_df.columns)\n",
    "\n",
    "import os\n",
    "from tqdm.notebook import tqdm  # For Jupyter notebook\n",
    "# OR\n",
    "# from tqdm import tqdm_notebook as tqdm  # Alternative import\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "if not os.path.exists('chat_by_state'):\n",
    "    os.makedirs('chat_by_state')\n",
    "\n",
    "# Get unique states and convert to list\n",
    "states = list(master_df.StateName.unique().compute())\n",
    "\n",
    "# Create separate CSV for each state with progress bar\n",
    "for state in tqdm(states, desc=\"Creating state-wise CSV files\"):\n",
    "    # Filter data for the state\n",
    "    state_df = master_df[master_df.StateName == state]\n",
    "    \n",
    "    # Create filename - replace spaces with underscores and convert to lowercase\n",
    "    filename = f\"chat_by_state/{state.replace(' ', '_').lower()}.csv\"\n",
    "    \n",
    "    # Save to CSV\n",
    "    state_df.compute().to_csv(filename, index=False)\n",
    "\n",
    "print(f\"\\nCompleted! All state files have been saved in 'chat_by_state' directory\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb = pd.read_csv('chat_by_state/west_bengal.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb_agri = wb[wb['Sector']=='AGRICULTURE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb_agri.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = wb_agri[wb_agri['Crop']=='0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mtn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
