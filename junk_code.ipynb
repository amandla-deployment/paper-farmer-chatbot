{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install \"dask[dataframe]\"\n",
    "# ! pip install \"dask[diagnostics]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/satyakama/Documents/paper-farmer-chatbot')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib as Path \n",
    "Path.Path.cwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names: Index(['BlockName', 'Category', 'Year', 'Month', 'Day', 'Crop', 'DistrictName',\n",
      "       'QueryType', 'Season', 'Sector', 'StateName', 'QueryText', 'KccAns'],\n",
      "      dtype='object')\n",
      "Original number of rows in masters_df: 41987874\n",
      "Original number of rows in cleaned_df_completeKccAns: 37667462\n"
     ]
    }
   ],
   "source": [
    "master_df = dd.read_csv('kcc_dataset.csv', dtype='object') \n",
    "\n",
    "print(f'Column names: {master_df.columns}')\n",
    "\n",
    "print(f'Original number of rows in masters_df: {len(master_df.compute())}')\n",
    "\n",
    "cleaned_df_completeKccAns = master_df.dropna(subset=['KccAns'])\n",
    "\n",
    "print(f'Original number of rows in cleaned_df_completeKccAns: {len(cleaned_df_completeKccAns.compute())}')\n",
    "\n",
    "# Drop all rows in which KccAns is NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows before filtering: 37667462\n",
      "Number of rows after filtering: 37636895\n",
      "Number of rows removed: 30567\n",
      "Percentage of rows removed: 0.08%\n"
     ]
    }
   ],
   "source": [
    "# Filter out rows containing 'Call Disconnected'\n",
    "cleaned_df_completeKccAns_dropCallDisconnected = cleaned_df_completeKccAns[\n",
    "    ~(cleaned_df_completeKccAns['QueryText'].str.contains('Call Disconnected', case=False, na=False)) &\n",
    "    ~(cleaned_df_completeKccAns['KccAns'].str.contains('Call Disconnected', case=False, na=False))\n",
    "]\n",
    "\n",
    "# Check the row counts\n",
    "original_count = len(cleaned_df_completeKccAns.compute())\n",
    "new_count = len(cleaned_df_completeKccAns_dropCallDisconnected.compute())\n",
    "\n",
    "print(f'Number of rows before filtering: {original_count}')\n",
    "print(f'Number of rows after filtering: {new_count}')\n",
    "print(f'Number of rows removed: {original_count - new_count}')\n",
    "print(f'Percentage of rows removed: {((original_count - new_count) / original_count * 100):.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative approach\n",
    "try:\n",
    "    # First materialize the column as a series\n",
    "    query_series = cleaned_df_completeKccAns_dropCallDisconnected['QueryText'].astype(str)  # ensure string type\n",
    "    \n",
    "    # Then get value counts\n",
    "    top_queries = query_series.value_counts().nlargest(10).compute()\n",
    "    \n",
    "    print(\"\\nTop 10 most frequent queries:\")\n",
    "    for query, count in top_queries.items():\n",
    "        print(f\"Count: {count}, Query: {query}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df_completeKccAns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = dd.read_csv('kcc_dataset.csv', dtype='object') \n",
    "\n",
    "print(f'Column names: {master_df.columns}')\n",
    "\n",
    "\n",
    "# Calculate the percentage of NaN values\n",
    "nan_percentage_kccAns = (master_df['KccAns'].isna().sum() / len(master_df) * 100).compute()\n",
    "\n",
    "print(f'Percentage of NaN values in KccAns: {nan_percentage_kccAns:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop column names\n",
    "master_df = master_df.drop(columns=['BlockName', 'Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count rows where any column has NaN\n",
    "rows_with_nan = master_df.isna().any(axis=1).sum().compute()\n",
    "\n",
    "# Get total number of rows\n",
    "total_rows = len(master_df.compute())\n",
    "\n",
    "# Calculate percentage\n",
    "nan_percentage = (rows_with_nan / total_rows) * 100\n",
    "\n",
    "print(f'Total number of rows: {total_rows}')\n",
    "print(f'Number of rows with at least one NaN: {rows_with_nan}')\n",
    "print(f'Percentage of rows with at least one NaN: {nan_percentage:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get NaN count for each column\n",
    "column_nan_counts = master_df.isna().sum().compute()\n",
    "column_nan_percentages = (column_nan_counts / total_rows * 100)\n",
    "\n",
    "print(\"\\nNaN distribution by column:\")\n",
    "for column in master_df.columns:\n",
    "    count = column_nan_counts[column]\n",
    "    percentage = column_nan_percentages[column]\n",
    "    print(f'{column}: {count} NaN values ({percentage:.2f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import dask.dataframe as dd\n",
    "\n",
    "import os\n",
    "import tqdm as tqdm\n",
    "\n",
    "\n",
    "# Reading all columns as strings\n",
    "master_df = dd.read_csv('kcc_dataset.csv', dtype='object') \n",
    "\n",
    "print(master_df.columns)\n",
    "\n",
    "import os\n",
    "from tqdm.notebook import tqdm  # For Jupyter notebook\n",
    "# OR\n",
    "# from tqdm import tqdm_notebook as tqdm  # Alternative import\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "if not os.path.exists('chat_by_state'):\n",
    "    os.makedirs('chat_by_state')\n",
    "\n",
    "# Get unique states and convert to list\n",
    "states = list(master_df.StateName.unique().compute())\n",
    "\n",
    "# Create separate CSV for each state with progress bar\n",
    "for state in tqdm(states, desc=\"Creating state-wise CSV files\"):\n",
    "    # Filter data for the state\n",
    "    state_df = master_df[master_df.StateName == state]\n",
    "    \n",
    "    # Create filename - replace spaces with underscores and convert to lowercase\n",
    "    filename = f\"chat_by_state/{state.replace(' ', '_').lower()}.csv\"\n",
    "    \n",
    "    # Save to CSV\n",
    "    state_df.compute().to_csv(filename, index=False)\n",
    "\n",
    "print(f\"\\nCompleted! All state files have been saved in 'chat_by_state' directory\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb = pd.read_csv('chat_by_state/west_bengal.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb_agri = wb[wb['Sector']=='AGRICULTURE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb_agri.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = wb_agri[wb_agri['Crop']=='0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mtn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
