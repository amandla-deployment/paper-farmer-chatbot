{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install \"dask[dataframe]\"\n",
    "# ! pip install \"dask[diagnostics]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/manimala/Documents/satyakama/paper-farmer-chatbot\n"
     ]
    }
   ],
   "source": [
    "import pathlib as Path \n",
    "print(f'Current working directory: {Path.Path.cwd()}')\n",
    "\n",
    "import dask.dataframe as dd # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of rows in master_df: 41987874\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "dtypes = {\n",
    "    'Year': np.int64,\n",
    "    'Month': np.int64,\n",
    "    'Day': np.int64,\n",
    "    'Crop': 'string[pyarrow]',\n",
    "    'DistrictName': 'string[pyarrow]',\n",
    "    'QueryType': 'string[pyarrow]',\n",
    "    'Season': 'string[pyarrow]',\n",
    "    'Sector': 'string[pyarrow]',\n",
    "    'StateName': 'string[pyarrow]',\n",
    "    'QueryText': 'string[pyarrow]',\n",
    "    'KccAns': 'string[pyarrow]',\n",
    "    'BlockName': 'string[pyarrow]',  # Added this\n",
    "    'Category': 'string[pyarrow]'    # Added this\n",
    "}\n",
    "\n",
    "master_df = dd.read_csv(\n",
    "    'dataset/original_dataset/kcc_dataset.csv',\n",
    "    dtype=dtypes,\n",
    "    blocksize='128MB',\n",
    "    usecols=lambda col: col not in ['BlockName', 'Category']\n",
    ")\n",
    "\n",
    "# Now get the row count\n",
    "row_count_master_df = master_df.shape[0].compute()\n",
    "\n",
    "print(f'Original number of rows in master_df: {row_count_master_df}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of rows in master_df_completeQApairs: 37665904\n"
     ]
    }
   ],
   "source": [
    "master_df_completeQApairs = master_df.dropna(subset=['QueryText', 'KccAns'])\n",
    "\n",
    "print(f'Original number of rows in master_df_completeQApairs: {master_df_completeQApairs.shape[0].compute()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 most frequent queries:\n",
      "Count: 4698473, Query: Farmer asked query on Weather\n",
      "Count: 832804, Query: TELL ME ABOUT WEATHER INFORMATION \n",
      "Count: 375914, Query: Asking about weather forecast\n",
      "Count: 213078, Query: weather report\n",
      "Count: 199469, Query: weather information\n",
      "Count: 193288, Query: Asking about weather forecast \n",
      "Count: 182086, Query: WEATHER REPORT\n",
      "Count: 178518, Query: TELL ME WEATHER INFORMATION\n",
      "Count: 177374, Query: WEATHER INFORMATION\n",
      "Count: 176098, Query: Weather information\n",
      "Count: 157399, Query: information regarding weather forecasting\n",
      "Count: 136110, Query: weather information \n",
      "Count: 127310, Query: weather\n",
      "Count: 99458, Query: Asked About SMS Activation\n",
      "Count: 97832, Query: Information regarding weather in \n"
     ]
    }
   ],
   "source": [
    "# Alternative approach\n",
    "try:\n",
    "    # First materialize the column as a series\n",
    "    query_series = master_df_completeQApairs['QueryText'].astype(str)  # ensure string type\n",
    "    \n",
    "    # Then get value counts\n",
    "    top_queries = query_series.value_counts().nlargest(15).compute()\n",
    "    \n",
    "    print(\"\\nTop 15 most frequent queries:\")\n",
    "    for query, count in top_queries.items():\n",
    "        print(f\"Count: {count}, Query: {query}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of top 10 queries as a set for faster lookup\n",
    "top_query_set = set(top_queries.index)\n",
    "\n",
    "# Create a filter to exclude top queries\n",
    "master_df_removeWeather = master_df_completeQApairs[~master_df_completeQApairs['QueryText'].isin(top_query_set)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of rows: 41,987,874\n",
      "Original number of rows in master_df_completeQApairs: 37665904\n",
      "Rows after removing top queries: 29,820,693\n"
     ]
    }
   ],
   "source": [
    "# Check the new size\n",
    "print(f'Original number of rows: {master_df.shape[0].compute():,}')\n",
    "print(f'Original number of rows in master_df_completeQApairs: {master_df_completeQApairs.shape[0].compute()}')\n",
    "print(f'Rows after removing top queries: {master_df_removeWeather.shape[0].compute():,}')\n",
    "# print(f'Rows removed: {(master_df_completeQApairs.shape[0].compute() - filtered_df.shape[0].compute()):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "857"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "# Delete previous large dataframes if they exist\n",
    "if 'master_df' in locals():\n",
    "    del master_df\n",
    "if 'master_df_completeQApairs' in locals():\n",
    "    del master_df_completeQApairs\n",
    "if 'query_series' in locals():\n",
    "    del query_series\n",
    "if 'top_queries' in locals():\n",
    "    del top_queries\n",
    "\n",
    "# Force garbage collection\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Unable to allocate 78.5 TiB for an array with shape (10289501,) and data type <U2097814\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Set a smaller number of partitions to reduce memory overhead\n",
    "    master_df_removeWeather = master_df_removeWeather.repartition(npartitions=100)\n",
    "    \n",
    "    # Process in chunks using map_partitions\n",
    "    top_queries_KccAns = (\n",
    "        master_df_removeWeather['KccAns']\n",
    "        .map_partitions(lambda x: x.value_counts())\n",
    "        .compute()\n",
    "        .nlargest(10)\n",
    "    )\n",
    "    \n",
    "    print(\"\\nTop 10 most frequent answers in KccAns:\")\n",
    "    for answer, count in top_queries_KccAns.items():\n",
    "        print(f\"Count: {count:,}, Answer: {answer}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Unable to allocate 3.53 TiB for an array with shape (462138,) and data type <U2097814\n"
     ]
    }
   ],
   "source": [
    "# Alternative approach\n",
    "try:\n",
    "    # First materialize the column as a series\n",
    "    query_series_KccAns = master_df_removeWeather['KccAns'].astype(str)  # ensure string type\n",
    "    \n",
    "    # Then get value counts\n",
    "    top_queries_KccAns = query_series_KccAns.value_counts().nlargest(10).compute()\n",
    "    \n",
    "    print(\"\\nTop 10 most frequent queries in KccAns:\")\n",
    "    for query, count in top_queries.items():\n",
    "        print(f\"Count: {count}, Query: {query}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Year', 'Month', 'Day', 'Crop', 'DistrictName', 'QueryType', 'Season',\n",
       "       'Sector', 'StateName', 'QueryText', 'KccAns'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df_removeWeather.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(top_queries.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out rows containing 'Call Disconnected'\n",
    "cleaned_df_completeQApairs_dropCallDisconnected = cleaned_df_completeQApairs[\n",
    "    ~(cleaned_df_completeQApairs['QueryText'].str.contains('Call Disconnected', case=False, na=False)) &\n",
    "    ~(cleaned_df_completeQApairs['KccAns'].str.contains('Call Disconnected', case=False, na=False))\n",
    "]\n",
    "\n",
    "# Check the row counts\n",
    "original_count = len(cleaned_df_completeKccAns.compute())\n",
    "new_count = len(cleaned_df_completeKccAns_dropCallDisconnected.compute())\n",
    "\n",
    "print(f'Number of rows before filtering: {original_count}')\n",
    "print(f'Number of rows after filtering: {new_count}')\n",
    "print(f'Number of rows removed: {original_count - new_count}')\n",
    "print(f'Percentage of rows removed: {((original_count - new_count) / original_count * 100):.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative approach\n",
    "try:\n",
    "    # First materialize the column as a series\n",
    "    query_series = cleaned_df_completeKccAns_dropCallDisconnected['QueryText'].astype(str)  # ensure string type\n",
    "    \n",
    "    # Then get value counts\n",
    "    top_queries = query_series.value_counts().nlargest(10).compute()\n",
    "    \n",
    "    print(\"\\nTop 10 most frequent queries:\")\n",
    "    for query, count in top_queries.items():\n",
    "        print(f\"Count: {count}, Query: {query}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df_completeKccAns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = dd.read_csv('kcc_dataset.csv', dtype='object') \n",
    "\n",
    "print(f'Column names: {master_df.columns}')\n",
    "\n",
    "\n",
    "# Calculate the percentage of NaN values\n",
    "nan_percentage_kccAns = (master_df['KccAns'].isna().sum() / len(master_df) * 100).compute()\n",
    "\n",
    "print(f'Percentage of NaN values in KccAns: {nan_percentage_kccAns:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop column names\n",
    "master_df = master_df.drop(columns=['BlockName', 'Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count rows where any column has NaN\n",
    "rows_with_nan = master_df.isna().any(axis=1).sum().compute()\n",
    "\n",
    "# Get total number of rows\n",
    "total_rows = len(master_df.compute())\n",
    "\n",
    "# Calculate percentage\n",
    "nan_percentage = (rows_with_nan / total_rows) * 100\n",
    "\n",
    "print(f'Total number of rows: {total_rows}')\n",
    "print(f'Number of rows with at least one NaN: {rows_with_nan}')\n",
    "print(f'Percentage of rows with at least one NaN: {nan_percentage:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get NaN count for each column\n",
    "column_nan_counts = master_df.isna().sum().compute()\n",
    "column_nan_percentages = (column_nan_counts / total_rows * 100)\n",
    "\n",
    "print(\"\\nNaN distribution by column:\")\n",
    "for column in master_df.columns:\n",
    "    count = column_nan_counts[column]\n",
    "    percentage = column_nan_percentages[column]\n",
    "    print(f'{column}: {count} NaN values ({percentage:.2f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import dask.dataframe as dd\n",
    "\n",
    "import os\n",
    "import tqdm as tqdm\n",
    "\n",
    "\n",
    "# Reading all columns as strings\n",
    "master_df = dd.read_csv('kcc_dataset.csv', dtype='object') \n",
    "\n",
    "print(master_df.columns)\n",
    "\n",
    "import os\n",
    "from tqdm.notebook import tqdm  # For Jupyter notebook\n",
    "# OR\n",
    "# from tqdm import tqdm_notebook as tqdm  # Alternative import\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "if not os.path.exists('chat_by_state'):\n",
    "    os.makedirs('chat_by_state')\n",
    "\n",
    "# Get unique states and convert to list\n",
    "states = list(master_df.StateName.unique().compute())\n",
    "\n",
    "# Create separate CSV for each state with progress bar\n",
    "for state in tqdm(states, desc=\"Creating state-wise CSV files\"):\n",
    "    # Filter data for the state\n",
    "    state_df = master_df[master_df.StateName == state]\n",
    "    \n",
    "    # Create filename - replace spaces with underscores and convert to lowercase\n",
    "    filename = f\"chat_by_state/{state.replace(' ', '_').lower()}.csv\"\n",
    "    \n",
    "    # Save to CSV\n",
    "    state_df.compute().to_csv(filename, index=False)\n",
    "\n",
    "print(f\"\\nCompleted! All state files have been saved in 'chat_by_state' directory\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb = pd.read_csv('chat_by_state/west_bengal.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb_agri = wb[wb['Sector']=='AGRICULTURE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb_agri.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = wb_agri[wb_agri['Crop']=='0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "satyakama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
